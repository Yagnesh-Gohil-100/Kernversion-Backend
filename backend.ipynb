{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Segmentation and Mapping\n",
    "- Segments images, enlarges them, and enhances their quality.\n",
    "- Generates a **row mapping list** and **coordinates list** for all segmented images.\n",
    "- Assigns a **row number** to each segmented image based on its position on the page for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 Row Mapping: [(1, 71, 78), (2, 105, 116), (3, 121, 136), (4, 144, 147), (5, 154, 170), (6, 174, 177), (7, 182, 188), (8, 221, 223), (9, 255, 261), (10, 288, 320), (11, 325, 328), (12, 337, 349), (13, 356, 359), (14, 363, 369), (15, 377, 386), (16, 392, 405), (17, 416, 419), (18, 426, 441), (19, 443, 445), (20, 446, 448), (21, 449, 452), (22, 453, 459), (23, 501, 504), (24, 541, 553), (25, 581, 590), (26, 596, 598), (27, 621, 629), (28, 635, 649), (29, 655, 658), (30, 665, 680), (31, 685, 689), (32, 693, 699), (33, 706, 715), (34, 721, 737), (35, 742, 745), (36, 752, 767), (37, 774, 776), (38, 779, 786)]\n",
      "Page 0 Coordinates: [(472, 783, 7, 6), (318, 782, 7, 7), (166, 782, 6, 7), (394, 781, 6, 7), (243, 780, 11, 10), (90, 779, 6, 12), (493, 774, 17, 5), (504, 759, 7, 11), (431, 759, 8, 12), (391, 759, 15, 13), (354, 759, 14, 12), (319, 759, 12, 16), (240, 758, 13, 12), (127, 758, 17, 13), (88, 758, 8, 12), (164, 757, 18, 20), (468, 754, 16, 19), (281, 754, 14, 18), (492, 753, 9, 15), (209, 752, 10, 20), (493, 742, 20, 6), (425, 729, 22, 16), (391, 729, 16, 12), (417, 728, 6, 17), (319, 728, 11, 13), (238, 728, 17, 12), (202, 728, 17, 13), (85, 728, 9, 13), (467, 725, 15, 23), (492, 723, 24, 18), (286, 722, 9, 19), (162, 722, 21, 25), (135, 722, 8, 17), (359, 721, 9, 20), (122, 710, 11, 10), (236, 706, 14, 17), (470, 696, 7, 7), (394, 695, 6, 9), (317, 695, 7, 7), (245, 695, 8, 7), (163, 694, 10, 9), (88, 693, 7, 11), (123, 687, 13, 4), (200, 686, 15, 5), (90, 685, 18, 6), (437, 674, 11, 13), (502, 673, 8, 12), (391, 673, 9, 14), (359, 672, 9, 13), (286, 672, 9, 12), (162, 672, 12, 13), (94, 671, 17, 11), (318, 668, 15, 17), (466, 667, 18, 19), (86, 667, 6, 14), (239, 666, 16, 19), (120, 666, 22, 16), (198, 665, 21, 18), (202, 655, 16, 6), (90, 655, 18, 6), (467, 643, 11, 13), (393, 642, 11, 14), (358, 642, 11, 13), (283, 642, 11, 13), (161, 642, 11, 13), (318, 641, 11, 14), (200, 641, 18, 9), (120, 638, 25, 23), (117, 638, 13, 14), (499, 637, 11, 18), (439, 637, 8, 18), (82, 637, 28, 15), (237, 635, 8, 19), (226, 626, 5, 161), (455, 625, 5, 168), (236, 625, 10, 9), (197, 624, 7, 9), (159, 624, 7, 9), (94, 624, 9, 9), (80, 624, 8, 9), (149, 623, 6, 167), (379, 622, 5, 168), (465, 621, 10, 13), (302, 621, 6, 166), (112, 621, 10, 11), (318, 596, 5, 5), (276, 581, 40, 19), (205, 546, 86, 14), (367, 544, 10, 15), (298, 544, 5, 15), (311, 541, 49, 16), (261, 501, 68, 6), (417, 455, 7, 7), (195, 455, 9, 8), (304, 454, 6, 10), (89, 453, 5, 9), (339, 449, 41, 6), (460, 446, 14, 5), (167, 443, 3, 5), (303, 433, 10, 16), (270, 433, 13, 12), (512, 432, 4, 13), (492, 432, 10, 13), (436, 432, 8, 12), (415, 432, 8, 12), (388, 432, 8, 12), (322, 432, 8, 12), (245, 432, 12, 13), (215, 432, 8, 13), (190, 432, 8, 12), (159, 432, 11, 9), (134, 432, 12, 13), (112, 432, 8, 12), (473, 431, 7, 11), (457, 431, 12, 10), (357, 431, 22, 12), (86, 428, 16, 17), (340, 426, 14, 15), (339, 416, 41, 6), (112, 404, 10, 3), (212, 403, 12, 4), (415, 399, 10, 13), (386, 399, 9, 13), (302, 399, 11, 13), (272, 399, 10, 13), (161, 399, 9, 13), (86, 399, 9, 12), (491, 398, 17, 13), (135, 398, 9, 13), (243, 396, 11, 16), (190, 395, 10, 17), (337, 394, 43, 13), (458, 393, 20, 24), (437, 392, 8, 17), (321, 392, 9, 17), (188, 381, 9, 10), (84, 378, 11, 13), (413, 377, 6, 14), (155, 377, 10, 14), (417, 366, 7, 6), (195, 365, 9, 9), (304, 364, 7, 9), (90, 363, 5, 9), (441, 357, 15, 5), (329, 356, 16, 6), (156, 356, 13, 4), (501, 343, 8, 12), (471, 343, 15, 12), (388, 343, 8, 12), (362, 343, 17, 12), (439, 342, 15, 11), (415, 342, 11, 13), (329, 342, 15, 11), (268, 342, 10, 13), (245, 342, 8, 12), (220, 342, 8, 13), (189, 342, 17, 13), (110, 342, 9, 15), (87, 342, 10, 13), (153, 341, 15, 12), (304, 337, 14, 21), (132, 337, 10, 18), (156, 326, 11, 4), (438, 325, 20, 6), (330, 325, 17, 5), (503, 317, 9, 4), (220, 316, 9, 4), (489, 312, 5, 15), (471, 312, 15, 16), (131, 312, 10, 13), (108, 312, 11, 12), (86, 312, 9, 13), (152, 311, 17, 10), (413, 308, 16, 16), (301, 308, 17, 16), (266, 308, 16, 16), (240, 308, 16, 16), (190, 308, 17, 16), (385, 307, 11, 17), (364, 306, 8, 16), (326, 306, 24, 14), (403, 299, 5, 164), (289, 299, 5, 167), (87, 297, 32, 7), (433, 294, 31, 27), (177, 290, 5, 169), (411, 289, 14, 15), (299, 288, 14, 15), (275, 255, 48, 13), (264, 221, 70, 5), (418, 184, 8, 7), (205, 184, 9, 9), (91, 183, 6, 11), (305, 182, 6, 10), (461, 174, 19, 6), (352, 174, 17, 6), (274, 162, 11, 12), (252, 162, 9, 12), (232, 162, 8, 12), (168, 162, 10, 12), (147, 162, 8, 11), (122, 162, 8, 12), (92, 162, 13, 16), (514, 161, 5, 13), (497, 161, 10, 12), (418, 161, 9, 12), (323, 161, 12, 13), (303, 161, 12, 12), (205, 161, 15, 14), (459, 160, 14, 9), (388, 160, 8, 12), (477, 159, 6, 12), (348, 156, 27, 13), (438, 154, 9, 18), (208, 154, 6, 5), (341, 144, 40, 6), (118, 134, 10, 4), (228, 133, 11, 5), (275, 129, 11, 12), (169, 129, 9, 12), (93, 129, 9, 12), (417, 128, 10, 13), (303, 128, 11, 13), (146, 128, 9, 13), (495, 127, 16, 12), (388, 127, 8, 13), (205, 125, 10, 16), (252, 123, 11, 18), (338, 122, 43, 14), (460, 121, 21, 25), (439, 121, 8, 18), (324, 121, 7, 18), (199, 111, 9, 10), (291, 108, 5, 77), (87, 108, 10, 13), (458, 106, 5, 11), (405, 106, 4, 84), (189, 106, 5, 83), (415, 105, 7, 15), (333, 71, 6, 14), (297, 71, 16, 12), (265, 71, 5, 14)]\n",
      "Page 1 Row Mapping: [(39, 54, 62), (40, 95, 102), (41, 107, 124), (42, 130, 132), (43, 139, 154), (44, 166, 174), (45, 209, 211), (46, 247, 254), (47, 275, 287), (48, 294, 308), (49, 314, 316), (50, 325, 341), (51, 346, 348), (52, 352, 360), (53, 366, 374), (54, 384, 396), (55, 402, 406), (56, 413, 430), (57, 433, 435), (58, 441, 448), (59, 456, 464), (60, 471, 486), (61, 491, 494), (62, 503, 517), (63, 522, 522), (64, 523, 525), (65, 531, 537), (66, 544, 555), (67, 561, 576), (68, 582, 584), (69, 593, 606), (70, 612, 615), (71, 620, 626), (72, 694, 697)]\n",
      "Page 1 Coordinates: [(262, 694, 73, 6), (469, 623, 7, 6), (318, 623, 8, 7), (244, 622, 10, 8), (164, 622, 7, 8), (396, 621, 6, 7), (87, 620, 6, 12), (204, 612, 17, 6), (512, 599, 5, 14), (494, 599, 11, 13), (365, 599, 8, 13), (317, 599, 8, 12), (289, 599, 8, 13), (238, 599, 18, 13), (85, 599, 8, 12), (469, 598, 7, 13), (439, 598, 8, 13), (394, 598, 8, 13), (201, 598, 11, 9), (216, 597, 6, 11), (161, 594, 16, 19), (129, 593, 13, 19), (202, 582, 16, 5), (85, 573, 11, 4), (287, 572, 11, 4), (239, 568, 10, 13), (180, 568, 6, 16), (162, 568, 16, 16), (498, 567, 17, 13), (363, 567, 11, 14), (305, 567, 5, 64), (201, 566, 18, 10), (437, 563, 15, 25), (127, 563, 15, 18), (317, 562, 8, 19), (469, 561, 7, 20), (393, 561, 8, 17), (290, 551, 33, 8), (434, 544, 7, 14), (165, 534, 6, 7), (469, 533, 7, 7), (318, 533, 7, 6), (246, 533, 8, 7), (396, 531, 6, 8), (89, 531, 6, 10), (435, 523, 16, 5), (324, 522, 2, 1), (133, 511, 10, 13), (212, 510, 9, 12), (85, 510, 8, 13), (502, 509, 8, 13), (469, 509, 7, 12), (394, 509, 19, 12), (367, 509, 8, 13), (283, 509, 11, 13), (240, 509, 9, 13), (437, 508, 15, 11), (163, 505, 10, 23), (317, 503, 15, 18), (432, 491, 19, 6), (86, 484, 10, 4), (469, 483, 10, 4), (210, 483, 11, 4), (363, 482, 11, 4), (164, 479, 11, 13), (133, 479, 10, 13), (394, 478, 10, 13), (281, 478, 12, 14), (317, 477, 9, 13), (499, 474, 17, 16), (240, 474, 17, 17), (429, 471, 24, 16), (497, 459, 9, 10), (393, 456, 10, 13), (160, 456, 13, 14), (470, 444, 6, 6), (246, 444, 9, 9), (165, 444, 8, 8), (319, 443, 7, 7), (89, 442, 5, 10), (397, 441, 6, 10), (247, 435, 1, 1), (435, 433, 16, 5), (133, 422, 10, 12), (289, 421, 8, 12), (240, 421, 15, 13), (162, 421, 10, 13), (86, 421, 8, 12), (394, 420, 9, 12), (364, 420, 11, 12), (198, 420, 18, 20), (469, 419, 8, 13), (319, 419, 8, 13), (446, 418, 6, 11), (435, 418, 7, 11), (505, 413, 12, 20), (198, 403, 19, 6), (435, 402, 16, 5), (471, 394, 8, 4), (287, 394, 10, 4), (394, 389, 9, 13), (506, 388, 9, 13), (366, 388, 9, 14), (317, 388, 12, 14), (211, 388, 8, 10), (433, 387, 18, 9), (162, 386, 17, 17), (135, 385, 8, 18), (84, 385, 8, 18), (240, 384, 15, 18), (193, 384, 15, 15), (393, 368, 9, 12), (81, 367, 14, 15), (495, 366, 9, 14), (320, 356, 7, 6), (163, 356, 8, 8), (469, 355, 7, 6), (247, 355, 8, 7), (87, 354, 6, 11), (396, 352, 7, 11), (202, 346, 17, 4), (85, 333, 11, 16), (240, 332, 13, 13), (161, 332, 14, 13), (133, 332, 9, 13), (359, 331, 15, 13), (317, 331, 12, 13), (290, 331, 7, 13), (468, 330, 9, 13), (437, 330, 10, 16), (396, 330, 8, 13), (205, 330, 15, 12), (499, 325, 15, 18), (203, 314, 16, 5), (286, 305, 10, 4), (394, 304, 9, 4), (84, 302, 10, 13), (164, 301, 10, 13), (130, 301, 11, 13), (201, 299, 18, 10), (317, 296, 17, 16), (239, 296, 17, 16), (468, 295, 16, 17), (433, 295, 17, 16), (359, 295, 16, 16), (499, 294, 17, 18), (458, 284, 6, 347), (83, 281, 9, 12), (227, 280, 5, 345), (158, 280, 10, 13), (148, 280, 7, 346), (305, 279, 5, 260), (381, 278, 6, 348), (491, 275, 14, 16), (467, 275, 14, 15), (270, 247, 50, 14), (263, 209, 72, 5), (319, 170, 6, 6), (245, 170, 9, 7), (166, 170, 6, 8), (470, 169, 6, 6), (88, 169, 5, 9), (395, 166, 7, 12), (133, 147, 9, 12), (85, 147, 14, 14), (207, 146, 8, 13), (320, 145, 9, 13), (288, 145, 9, 12), (243, 145, 18, 13), (503, 144, 11, 13), (469, 144, 8, 12), (441, 144, 9, 12), (393, 144, 8, 13), (365, 144, 8, 13), (164, 139, 8, 18), (170, 130, 5, 4), (94, 130, 6, 5), (205, 120, 11, 4), (286, 118, 10, 5), (164, 115, 10, 11), (131, 115, 11, 19), (243, 114, 9, 13), (364, 113, 9, 14), (320, 113, 11, 14), (498, 112, 17, 13), (83, 111, 17, 17), (434, 108, 16, 24), (92, 108, 1, 2), (468, 107, 7, 16), (392, 107, 8, 16), (149, 102, 5, 77), (459, 99, 5, 80), (226, 98, 5, 85), (83, 97, 10, 10), (304, 96, 5, 82), (391, 95, 10, 8), (381, 95, 4, 85), (314, 95, 8, 10), (297, 57, 7, 10), (260, 55, 5, 14), (288, 54, 5, 11)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import fitz\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to the entire image\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    \n",
    "    # Adaptive thresholding on blurred image\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "\n",
    "    # Morphological closing to connect broken parts of characters\n",
    "    closing_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, closing_kernel)\n",
    "\n",
    "    # Apply erosion to separate vertical lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    eroded = cv2.erode(closed, kernel, iterations=1)\n",
    "    \n",
    "    return eroded\n",
    "\n",
    "def enlarge_image(image, scale_factor=3):\n",
    "    enlarged_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return enlarged_image\n",
    "\n",
    "def enhance_quality(image):\n",
    "    sharpened = cv2.filter2D(image, -1, np.array([[-1, -1, -1], [-1,  9, -1], [-1, -1, -1]]))\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 10, 10, 7, 21)\n",
    "    return denoised\n",
    "\n",
    "def create_mapping(coordinates, aspect_ratio_threshold, is_row=True):\n",
    "    mapping = []\n",
    "    number = 1\n",
    "\n",
    "    if not coordinates:\n",
    "        return mapping\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(coordinates):\n",
    "        if is_row:\n",
    "            if h / w > aspect_ratio_threshold:\n",
    "                continue\n",
    "            coord = y\n",
    "            size = h\n",
    "        else:\n",
    "            if w / h > aspect_ratio_threshold and w > 14 and h < 8:  \n",
    "                continue\n",
    "            coord = x\n",
    "            size = w\n",
    "\n",
    "        if i == 0:\n",
    "            upper_limit = coord + int(size / 2)\n",
    "            lower_limit = coord\n",
    "            mapping.append((number, lower_limit, upper_limit))\n",
    "        elif mapping and coord > mapping[-1][2]:\n",
    "            number += 1\n",
    "            lower_limit = coord\n",
    "            upper_limit = coord + int(size / 2)\n",
    "            mapping.append((number, lower_limit, upper_limit))\n",
    "        else:\n",
    "            upper_limit = max(mapping[-1][2], coord + int(size / 2))\n",
    "            mapping[-1] = (number, mapping[-1][1], upper_limit)\n",
    "\n",
    "    return mapping\n",
    "\n",
    "def assign_number(coord, mapping):\n",
    "    for num, lower_limit, upper_limit in mapping:\n",
    "        if lower_limit <= coord <= upper_limit:\n",
    "            return num\n",
    "    return -1\n",
    "\n",
    "def extract_alphabets(pdf_path, output_folder, aspect_ratio_threshold=3):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    all_coordinates = []  # To store coordinates for all pages\n",
    "    all_row_mappings = []  # To store row mappings for all pages\n",
    "    last_row_number = 0  # To ensure row numbers continue across pages\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        page_image = page.get_pixmap()\n",
    "        np_page_image = np.frombuffer(page_image.samples, dtype=np.uint8).reshape((page_image.height, page_image.width, page_image.n))\n",
    "\n",
    "        processed_image = preprocess_image(np_page_image)\n",
    "\n",
    "        contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Extract coordinates for the current page\n",
    "        coordinates = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            coordinates.append((x, y, w, h))\n",
    "\n",
    "        if not coordinates:\n",
    "            print(f\"No contours found on page {page_num}.\")\n",
    "            all_coordinates.append([])\n",
    "            all_row_mappings.append([])\n",
    "            continue\n",
    "\n",
    "        # Sort coordinates by y-axis (rows)\n",
    "        coordinates_sorted_by_y = sorted(coordinates, key=lambda item: item[1])\n",
    "\n",
    "        # Create row mapping for the current page\n",
    "        row_mapping = create_mapping(coordinates_sorted_by_y, aspect_ratio_threshold, is_row=True)\n",
    "\n",
    "        # Adjust row numbers to continue from the last row number of the previous page\n",
    "        adjusted_row_mapping = []\n",
    "        for num, lower_limit, upper_limit in row_mapping:\n",
    "            adjusted_row_mapping.append((num + last_row_number, lower_limit, upper_limit))\n",
    "\n",
    "        # Update last_row_number for the next page\n",
    "        last_row_number = adjusted_row_mapping[-1][0] if adjusted_row_mapping else last_row_number\n",
    "\n",
    "        # Store coordinates and row mapping for the current page\n",
    "        all_coordinates.append(coordinates)\n",
    "        all_row_mappings.append(adjusted_row_mapping)\n",
    "\n",
    "        # Print row mapping and coordinates for the current page\n",
    "        print(f\"Page {page_num} Row Mapping:\", adjusted_row_mapping)\n",
    "        print(f\"Page {page_num} Coordinates:\", coordinates)\n",
    "\n",
    "        # Process and save alphabet regions for the current page\n",
    "        for (x, y, w, h) in coordinates:\n",
    "            if h / w > aspect_ratio_threshold:\n",
    "                continue\n",
    "\n",
    "            row_num = assign_number(y, adjusted_row_mapping)\n",
    "\n",
    "            if row_num == -1:\n",
    "                continue\n",
    "\n",
    "            alphabet_region = np_page_image[y:y+h, x:x+w]\n",
    "            enlarged_region = enlarge_image(alphabet_region)\n",
    "            enhanced_region = enhance_quality(enlarged_region)\n",
    "\n",
    "            if w < 6 and h < 6:\n",
    "                continue\n",
    "\n",
    "            base_filename = f\"{page_num}_row{row_num}_x{x}_y{y}_w{w}_h{h}\"\n",
    "            counter = 1\n",
    "            filename = f\"{base_filename}.png\"\n",
    "            while os.path.exists(os.path.join(output_folder, filename)):\n",
    "                filename = f\"{base_filename}_{counter}.png\"\n",
    "                counter += 1\n",
    "\n",
    "            alphabet_image = Image.fromarray(enhanced_region)\n",
    "            alphabet_image.save(os.path.join(output_folder, filename))\n",
    "    \n",
    "    return all_coordinates, all_row_mappings\n",
    "\n",
    "pdf_path = \"Analysis/multiple_page.pdf\"\n",
    "output_folder = \"Analysis/multiple_page\"\n",
    "all_coordinates, all_row_mappings = extract_alphabets(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Select Range of Row Numbers\n",
    "- Accepts user input to specify the range of row numbers containing the **full composition**.\n",
    "- Processes only the selected rows for further analysis and conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = 24\n",
    "last_row = 72\n",
    "\n",
    "# start_row = 1\n",
    "# end_row = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def get_image_details_with_row(filename):\n",
    "    pattern = r'(\\d+)_row(\\d+)_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        page_num = int(match.group(1))\n",
    "        row_num = int(match.group(2))\n",
    "        x = int(match.group(3))\n",
    "        y = int(match.group(4))\n",
    "        w = int(match.group(5))\n",
    "        h = int(match.group(6))\n",
    "        return (page_num, row_num, x, y, w, h)\n",
    "    return None\n",
    "\n",
    "def copy_images_in_row_range(input_folder, output_folder, first_row, last_row):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        details = get_image_details_with_row(filename)\n",
    "        if details:\n",
    "            _, row_num, _, _, _, _ = details\n",
    "            if first_row <= row_num <= last_row:\n",
    "                shutil.copy(os.path.join(input_folder, filename), os.path.join(output_folder, filename))\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"Analysis/multiple_page\"\n",
    "output_folder = \"Analysis/multiple_page/temp\"\n",
    "\n",
    "copy_images_in_row_range(input_folder, output_folder, first_row, last_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taal information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store taal information\n",
    "taal_info = {\n",
    "    \"Rupak\": {\n",
    "        \"beat_count\": 7,\n",
    "        \"divisions\": [3, 2, 2],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"3\"],\n",
    "        \"time_signature\": \"7/8\"  # 7 beats, divided into 3+2+2\n",
    "    },\n",
    "    \"Sultaal\": {\n",
    "        \"beat_count\": 10,\n",
    "        \"divisions\": [2, 2, 2, 2, 2],\n",
    "        \"vibhaag\": [\"X\", \"0\", \"2\", \"3\", \"0\"],\n",
    "        \"time_signature\": \"10/8\"  # 10 beats, divided into 2+2+2+2+2\n",
    "    },\n",
    "    \"Chautaal\": {\n",
    "        \"beat_count\": 12,\n",
    "        \"divisions\": [2, 2, 2, 2, 2, 2],\n",
    "        \"vibhaag\": [\"X\", \"0\", \"2\", \"0\", \"3\", \"4\"],\n",
    "        \"time_signature\": \"12/8\"  # 12 beats, divided into 2+2+2+2+2+2\n",
    "    },\n",
    "    \"Ada Chautaal\": {\n",
    "        \"beat_count\": 14,\n",
    "        \"divisions\": [2, 2, 2, 2, 2, 2, 2],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\", \"0\", \"4\", \"0\"],\n",
    "        \"time_signature\": \"14/8\"  # 14 beats, divided into 2+2+2+2+2+2+2\n",
    "    },\n",
    "    \"Jhoomra\": {\n",
    "        \"beat_count\": 14,\n",
    "        \"divisions\": [3, 4, 3, 4],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"14/8\"  # 14 beats, divided into 3+4+3+4\n",
    "    },\n",
    "    \"Dhamaar\": {\n",
    "        \"beat_count\": 14,\n",
    "        \"divisions\": [5, 2, 3, 4],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"14/8\"  # 14 beats, divided into 5+2+3+4\n",
    "    },\n",
    "    \"Deepchandi\": {\n",
    "        \"beat_count\": 14,\n",
    "        \"divisions\": [3, 4, 3, 4],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"14/8\"  # 14 beats, divided into 3+4+3+4\n",
    "    },\n",
    "    \"Punjabi (Tilwada)\": {\n",
    "        \"beat_count\": 16,\n",
    "        \"divisions\": [4, 4, 4, 4],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"16/8\"  # 16 beats, divided into 4+4+4+4\n",
    "    },\n",
    "    \"Dadra\": {\n",
    "        \"beat_count\": 6,\n",
    "        \"divisions\": [3, 3],\n",
    "        \"vibhaag\": [\"X\", \"0\"],\n",
    "        \"time_signature\": \"6/8\"  # 6 beats, divided into 3+3\n",
    "    },\n",
    "    \"Jhaptal\": {\n",
    "        \"beat_count\": 10,\n",
    "        \"divisions\": [2, 3, 2, 3],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"10/8\"  # 10 beats, divided into 2+3+2+3\n",
    "    },\n",
    "    \"Ektaal\": {\n",
    "        \"beat_count\": 12,\n",
    "        \"divisions\": [2, 2, 2, 2, 2, 2],\n",
    "        \"vibhaag\": [\"X\", \"0\", \"2\", \"0\", \"3\", \"4\"],\n",
    "        \"time_signature\": \"12/8\"  # 12 beats, divided into 2+2+2+2+2+2\n",
    "    },\n",
    "    \"Teentaal\": {\n",
    "        \"beat_count\": 16,\n",
    "        \"divisions\": [4, 4, 4, 4],\n",
    "        \"vibhaag\": [\"X\", \"2\", \"0\", \"3\"],\n",
    "        \"time_signature\": \"16/8\"  # 16 beats, divided into 4+4+4+4\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the taal for the composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "taal_name = \"Ektaal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show valid positions for the sam beat and take the input from user for sam beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Sam positions for Ektaal: [1, 3, 5, 7, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "def calculate_valid_sam_positions(taal_name):\n",
    "    \"\"\"\n",
    "    Calculate all valid positions where the sam (X) can occur for a given taal.\n",
    "    \"\"\"\n",
    "    if taal_name not in taal_info:\n",
    "        raise ValueError(f\"Taal '{taal_name}' not found in the database.\")\n",
    "    \n",
    "    # Get the divisions for the taal\n",
    "    divisions = taal_info[taal_name][\"divisions\"]\n",
    "    \n",
    "    # Calculate valid sam positions\n",
    "    valid_positions = [1]  # The first beat is always valid\n",
    "    cumulative_sum = 0\n",
    "    \n",
    "    # Start from the end of the divisions and add cumulatively\n",
    "    for i in range(len(divisions) - 1, -1, -1):\n",
    "        cumulative_sum += divisions[i]\n",
    "        if cumulative_sum < taal_info[taal_name][\"beat_count\"]:\n",
    "            valid_positions.append(cumulative_sum + 1)\n",
    "    \n",
    "    return sorted(valid_positions)\n",
    "\n",
    "def calculate_divisions_and_vibhaag(taal_name, sam_beat):\n",
    "    \"\"\"\n",
    "    Calculate the divisions and vibhaag for the given taal and sam beat.\n",
    "    \"\"\"\n",
    "    if taal_name not in taal_info:\n",
    "        raise ValueError(f\"Taal '{taal_name}' not found in the database.\")\n",
    "    \n",
    "    # Get the divisions and vibhaag for the taal\n",
    "    divisions = taal_info[taal_name][\"divisions\"]\n",
    "    vibhaag = taal_info[taal_name][\"vibhaag\"]\n",
    "    \n",
    "    # If sam is at the first beat, no change is needed\n",
    "    if sam_beat == 1:\n",
    "        return divisions, vibhaag\n",
    "    \n",
    "    # Calculate the rotation index\n",
    "    cumulative_sum = 0\n",
    "    rotation_index = 0\n",
    "    \n",
    "    # Start from the end of the divisions and add cumulatively\n",
    "    for i in range(len(divisions) - 1, -1, -1):\n",
    "        cumulative_sum += divisions[i]\n",
    "        if cumulative_sum + 1 == sam_beat:\n",
    "            rotation_index = i\n",
    "            break\n",
    "    \n",
    "    # Rotate divisions and vibhaag\n",
    "    new_divisions = divisions[rotation_index:] + divisions[:rotation_index]\n",
    "    new_vibhaag = vibhaag[rotation_index:] + vibhaag[:rotation_index]\n",
    "    \n",
    "    return new_divisions, new_vibhaag\n",
    "\n",
    "\n",
    "valid_positions = calculate_valid_sam_positions(taal_name)\n",
    "print(f\"Valid Sam positions for {taal_name}: {valid_positions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_beat = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Taal: Ektaal\n",
      "Total number of beats: 12\n",
      "Sam (X) at beat: 5\n",
      "New Divisions: [2, 2, 2, 2, 2, 2]\n",
      "New Vibhaag: ['3', '4', 'X', '0', '2', '0']\n"
     ]
    }
   ],
   "source": [
    "# Calculate divisions and vibhaag\n",
    "new_divisions, new_vibhaag = calculate_divisions_and_vibhaag(taal_name, sam_beat)\n",
    "\n",
    "# Define the beat count (size of the lists) from taal information\n",
    "beat_count = taal_info[taal_name][\"beat_count\"]\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nTaal: {taal_name}\")\n",
    "print(f\"Total number of beats: {beat_count}\")\n",
    "print(f\"Sam (X) at beat: {sam_beat}\")\n",
    "print(f\"New Divisions: {new_divisions}\")\n",
    "print(f\"New Vibhaag: {new_vibhaag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Image Count for Each Row\n",
    "- Counts the number of images in each row by processing the segmented image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_row_image_counts(folder_path):\n",
    "    \"\"\"\n",
    "    Calculate the number of images for each row in the folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing segmented images.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are row numbers and values are the number of images in that row.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the count of images for each row\n",
    "    row_image_count = defaultdict(int)\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file matches the expected format\n",
    "        if filename.endswith(\".png\"):  # Assuming images are in PNG format\n",
    "            # Extract row number from the filename\n",
    "            try:\n",
    "                parts = filename.split(\"_\")\n",
    "                row_num = int(parts[1].replace(\"row\", \"\"))  # Extract row number\n",
    "            except (IndexError, ValueError):\n",
    "                # Skip files that don't match the expected format\n",
    "                continue\n",
    "\n",
    "            # Increment the count for this row\n",
    "            row_image_count[row_num] += 1\n",
    "\n",
    "    return row_image_count\n",
    "\n",
    "\n",
    "folder_path = \"Analysis/multiple_page/temp\"\n",
    "\n",
    "# Get image counts for all rows\n",
    "row_image_count = get_row_image_counts(folder_path)\n",
    "\n",
    "# # Print the image counts for all rows\n",
    "# print(\"Image Counts for All Rows:\")\n",
    "# for row_num in sorted(row_image_count.keys()):\n",
    "#     print(f\"Row {row_num}: {row_image_count[row_num]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Rows with Sam, Taalis, and Khali\n",
    "- Creates a list of rows that could represent Sam, Taalis, and Khali based on the number of images in each row.\n",
    "- Uses the given taal information to determine the expected number of images for these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important Rows: [32, 38, 44, 52, 58, 65, 71]\n"
     ]
    }
   ],
   "source": [
    "def get_important_rows(row_image_count, taal_name):\n",
    "    \"\"\"\n",
    "    Calculate important rows based on the number of images in each row and the taal info.\n",
    "\n",
    "    Args:\n",
    "        row_image_count (dict): A dictionary where keys are row numbers and values are the number of images in that row.\n",
    "        taal_name (str): The name of the taal (e.g., \"Rupak\").\n",
    "        start_row (int): The starting row number (inclusive).\n",
    "        end_row (int): The ending row number (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of row numbers that are considered important (rows with exactly `divisions_size` images).\n",
    "    \"\"\"\n",
    "    # Get the size of the divisions list from taal_info\n",
    "    divisions_size = len(taal_info[taal_name][\"divisions\"])\n",
    "\n",
    "    # Create the important_rows list\n",
    "    important_rows = [\n",
    "        row_num for row_num, count in row_image_count.items()\n",
    "        if count == divisions_size\n",
    "    ]\n",
    "\n",
    "    return important_rows\n",
    "\n",
    "# Get important rows\n",
    "important_rows = get_important_rows(row_image_count, taal_name)\n",
    "print(\"Important Rows:\", important_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Correction: Update Identified Rows\n",
    "- Allows the user to review and correct the automatically identified rows for Sam, Taalis, and Khali.\n",
    "- Users can:\n",
    "  - Add missing rows.\n",
    "  - Remove incorrectly identified rows.\n",
    "  - Update the list to ensure accuracy.\n",
    "- Uses the corrected row numbers to create **subgroups**, where each subgroup includes:\n",
    "  - A **swar row**.\n",
    "  - Optional **kann swar**, **lyrics**, and **articulation rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_rows = [32, 38, 44, 52, 58, 65, 71] # multiple pages full composition\n",
    "\n",
    "# important_rows = [7, 14, 22] # multiple pages 1st part (some half portion of other composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Subgroup Creation and Assigning Column Numbers\n",
    "- Finds the first valid row in each subgroup.\n",
    "- Assigns `extra` for images that are not part of the composition (noise and metadata).\n",
    "- Assigns `column numbers` for valid images that are part of the composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup range: [24, 32]\n",
      "First valid row in subgroup:  26\n",
      "Subgroup range: [33, 38]\n",
      "First valid row in subgroup:  33\n",
      "Subgroup range: [39, 44]\n",
      "First valid row in subgroup:  39\n",
      "Subgroup range: [45, 52]\n",
      "First valid row in subgroup:  47\n",
      "Subgroup range: [53, 58]\n",
      "First valid row in subgroup:  53\n",
      "Subgroup range: [59, 65]\n",
      "First valid row in subgroup:  59\n",
      "Subgroup range: [66, 71]\n",
      "First valid row in subgroup:  66\n",
      "Subgroup Ranges: [(26, 31), (33, 37), (39, 43), (47, 51), (53, 57), (59, 64), (66, 70)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_details(filename):\n",
    "    pattern = r'(\\d+)_row(\\d+)_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        page_num = int(match.group(1))\n",
    "        row_num = int(match.group(2))\n",
    "        x = int(match.group(3))\n",
    "        y = int(match.group(4))\n",
    "        w = int(match.group(5))\n",
    "        h = int(match.group(6))\n",
    "        return (page_num, row_num, x, y, w, h)\n",
    "    return None\n",
    "\n",
    "def update_image_filename(output_folder, old_filename, new_suffix):\n",
    "    details = get_image_details(old_filename)\n",
    "    if details:\n",
    "        page_num, row_num, x, y, w, h = details\n",
    "        new_filename = f\"{page_num}_row{row_num}_{new_suffix}_x{x}_y{y}_w{w}_h{h}.png\"\n",
    "        os.rename(os.path.join(output_folder, old_filename), os.path.join(output_folder, new_filename))\n",
    "\n",
    "def find_general_boundaries(coordinates):\n",
    "    min_x = min(coordinates, key=lambda item: item[3])[3]\n",
    "    max_x = max(coordinates, key=lambda item: item[3] + item[5])[3] + max(coordinates, key=lambda item: item[3] + item[5])[5]\n",
    "    return min_x, max_x\n",
    "\n",
    "def is_row_centered(row_coords, general_min_x, general_max_x, threshold=0.15):\n",
    "    min_x = min(row_coords, key=lambda item: item[0])[0]\n",
    "    max_x = max(row_coords, key=lambda item: item[0] + item[2])[0] + max(row_coords, key=lambda item: item[0] + item[2])[2]\n",
    "    \n",
    "    center_region_left = general_min_x + (general_max_x - general_min_x) * threshold\n",
    "    center_region_right = general_max_x - (general_max_x - general_min_x) * threshold\n",
    "    \n",
    "    return center_region_left <= min_x and max_x <= center_region_right\n",
    "\n",
    "def find_first_valid_row(coordinates, row_mapping, subgroup_lower_bound):\n",
    "    general_min_x, general_max_x = find_general_boundaries(coordinates)\n",
    "    first_valid_row = None\n",
    "    \n",
    "    for i, (row_num, lower_limit, upper_limit) in enumerate(row_mapping):\n",
    "        if row_num < subgroup_lower_bound:\n",
    "            continue\n",
    "        \n",
    "        row_coords = [(x, y, w, h) for _, _, _, x, y, w, h in coordinates if lower_limit <= y <= upper_limit]\n",
    "        \n",
    "        if len(row_coords) >= 1:  # Ensure there is at least one image in the row\n",
    "            if not is_row_centered(row_coords, general_min_x, general_max_x):\n",
    "                if first_valid_row is None:\n",
    "                    first_valid_row = row_num\n",
    "                    # Check the previous row only if the first valid row is not the lower bound of the subgroup\n",
    "                    \n",
    "                    if row_num > subgroup_lower_bound:\n",
    "                        if i > 0:\n",
    "                            prev_row_num, prev_lower_limit, prev_upper_limit = row_mapping[i-1]\n",
    "                            prev_row_coords = [(x, y, w, h) for _, _, _, x, y, w, h in coordinates if prev_lower_limit <= y <= prev_upper_limit]\n",
    "\n",
    "                            if len(prev_row_coords) > 2:\n",
    "                                return prev_row_num\n",
    "                            elif len(prev_row_coords) <= 2:\n",
    "                                valid_prev_row = False\n",
    "                                for (x, y, w, h) in prev_row_coords:\n",
    "                                    if ((w / h > 1.6) and h > 8) or (w < 5):\n",
    "                                        valid_prev_row = True\n",
    "                                        break\n",
    "                                if not valid_prev_row:\n",
    "                                    return prev_row_num\n",
    "                    return first_valid_row\n",
    "                else:\n",
    "                    return first_valid_row\n",
    "    return None  # In case no valid row is found\n",
    "\n",
    "# def assign_number(coord, mapping):\n",
    "#     for num, lower_limit, upper_limit in mapping:\n",
    "#         if lower_limit <= coord <= upper_limit:\n",
    "#             return num\n",
    "#     return -1\n",
    "\n",
    "def assign_column_numbers(output_folder, all_row_mappings, first_row, important_rows, aspect_ratio_threshold=1.6):\n",
    "    images = os.listdir(output_folder)\n",
    "    coordinates = []\n",
    "    subgroup_ranges = []  # Store subgroup ranges\n",
    "\n",
    "    # Filter images within the start_row and end_row range\n",
    "    for image in images:\n",
    "        details = get_image_details(image)\n",
    "        if details:\n",
    "            page_num, row_num, x, y, w, h = details\n",
    "            coordinates.append((image, page_num, row_num, x, y, w, h))\n",
    "\n",
    "    # Flatten row_mapping for the rows within the range\n",
    "    flattened_row_mapping = []\n",
    "    for row_mapping in all_row_mappings:\n",
    "        for row_num, lower_limit, upper_limit in row_mapping:\n",
    "            # if start_row <= row_num <= end_row:\n",
    "            flattened_row_mapping.append((row_num, lower_limit, upper_limit))\n",
    "\n",
    "    # Sort flattened_row_mapping by row_num\n",
    "    flattened_row_mapping = sorted(flattened_row_mapping, key=lambda item: item[0])\n",
    "\n",
    "    # Adjust important_rows to include the start_row\n",
    "    # important_rows = [start_row - 1] + [row for row in important_rows if start_row <= row <= end_row]\n",
    "    important_rows = [first_row - 1] + important_rows\n",
    "\n",
    "    for i in range(len(important_rows) - 1):\n",
    "        start_subgroup = important_rows[i] + 1\n",
    "        end_subgroup = important_rows[i + 1]\n",
    "        subgroup_coords = [\n",
    "            (image, page_num, row_num, x, y, w, h) for image, page_num, row_num, x, y, w, h in coordinates\n",
    "            if start_subgroup <= row_num <= end_subgroup\n",
    "        ]\n",
    "        if not subgroup_coords:\n",
    "            continue\n",
    "        \n",
    "        # Print the current subgroup range\n",
    "        print(f\"Subgroup range: [{start_subgroup}, {end_subgroup}]\")\n",
    "        \n",
    "        # Find and mark invalid rows in the subgroup\n",
    "        invalid_rows = []\n",
    "        first_valid_row_in_subgroup = find_first_valid_row(subgroup_coords, flattened_row_mapping, start_subgroup)\n",
    "\n",
    "        # Print the first valid row in the subgroup\n",
    "        print(\"First valid row in subgroup: \", first_valid_row_in_subgroup)\n",
    "\n",
    "        # Store the current subgroup range as a tuple\n",
    "        subgroup_ranges.append((first_valid_row_in_subgroup, end_subgroup - 1))\n",
    "        \n",
    "        for image, page_num, row_num, x, y, w, h in subgroup_coords:\n",
    "            if row_num < first_valid_row_in_subgroup:\n",
    "                invalid_rows.append(image)\n",
    "                update_image_filename(output_folder, image, \"extra\")\n",
    "        \n",
    "        # Filter out invalid rows\n",
    "        valid_subgroup_coords = [\n",
    "            (image, page_num, row_num, x, y, w, h) for image, page_num, row_num, x, y, w, h in subgroup_coords\n",
    "            if row_num >= first_valid_row_in_subgroup\n",
    "        ]\n",
    "        \n",
    "        if not valid_subgroup_coords:\n",
    "            continue\n",
    "        \n",
    "        valid_subgroup_coords_sorted_by_x = sorted(valid_subgroup_coords, key=lambda item: item[3])  # Sort by x\n",
    "\n",
    "        # Extract (x, y, w, h) for create_mapping\n",
    "        valid_subgroup_coords_mapping = [\n",
    "            (x, y, w, h) for _, _, _, x, y, w, h in valid_subgroup_coords_sorted_by_x\n",
    "        ]\n",
    "\n",
    "        column_mapping = create_mapping(valid_subgroup_coords_mapping, aspect_ratio_threshold, is_row=False)\n",
    "\n",
    "        for image, page_num, row_num, x, y, w, h in valid_subgroup_coords_sorted_by_x:\n",
    "            col_num = assign_number(x, column_mapping)\n",
    "            if col_num != -1:\n",
    "                update_image_filename(output_folder, image, f\"col{col_num}\")\n",
    "        \n",
    "    return subgroup_ranges\n",
    "\n",
    "# Call the function\n",
    "subgroup_ranges = assign_column_numbers(output_folder, all_row_mappings, first_row, important_rows)\n",
    "print(\"Subgroup Ranges:\", subgroup_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the subgroup if required\n",
    "- When there is subgroup not having corresponding sam and taalis row (1st subgroup in most of the case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Subgroup range: [26, 31]\n",
      "Updated Subgroup range: [33, 37]\n",
      "Updated Subgroup range: [39, 43]\n",
      "Updated Subgroup range: [47, 51]\n",
      "Updated Subgroup range: [53, 57]\n",
      "Updated Subgroup range: [59, 64]\n",
      "Updated Subgroup range: [66, 70]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_image_details(filename):\n",
    "    \"\"\"\n",
    "    Extract row and column details from image filename.\n",
    "    Filename format: '0_row4_col12_x400_y145_w7_h10' or '0_row3_extra_x282_y116_w40_h18'\n",
    "    Returns (row_num, col_num).\n",
    "    \"\"\"\n",
    "    parts = filename.split('_')\n",
    "    row_num = None\n",
    "    col_num = None\n",
    "\n",
    "    for part in parts:\n",
    "        if part.startswith('row'):\n",
    "            row_num = int(part[3:])\n",
    "        elif part.startswith('col'):\n",
    "            col_num = int(part[3:])  # Ensure col_num gets a value only if it exists\n",
    "    \n",
    "    return row_num, col_num\n",
    "\n",
    "def process_subgroups(folder, subgroups):\n",
    "    \"\"\"\n",
    "    Processes subgroups by checking if the first subgroup needs to be split into two.\n",
    "    \"\"\"\n",
    "    images = os.listdir(folder)\n",
    "    images.sort(key=lambda x: get_image_details(x)[0])  # Sort by row number\n",
    "    \n",
    "    first_subgroup_start, first_subgroup_end = subgroups[0]\n",
    "    first_valid_row = first_subgroup_start\n",
    "\n",
    "    # Only process rows from the first valid row\n",
    "    first_group_images = [img for img in images if get_image_details(img)[0] >= first_valid_row]\n",
    "\n",
    "    # To track if we need to split the first subgroup\n",
    "    first_row_images = [img for img in first_group_images if get_image_details(img)[0] == first_valid_row]\n",
    "    second_row_images = [img for img in first_group_images if get_image_details(img)[0] == first_valid_row + 1]\n",
    "\n",
    "    # Ensure we have valid rows and columns to process\n",
    "    if first_row_images and second_row_images:\n",
    "        # Sort images by column number and check the first (lowest column number) image\n",
    "        first_row_images.sort(key=lambda x: get_image_details(x)[1])\n",
    "        second_row_images.sort(key=lambda x: get_image_details(x)[1])\n",
    "        \n",
    "        first_row_col = get_image_details(first_row_images[0])[1]\n",
    "        second_row_col = get_image_details(second_row_images[0])[1]\n",
    "\n",
    "        if first_row_col is not None and second_row_col is not None and first_row_col > 1 and second_row_col > 1:\n",
    "            # Now, let's iterate through rows to find where col = 1 begins\n",
    "            new_first_end = first_valid_row  # Default in case we find no rows with col = 1\n",
    "            for img in first_group_images:\n",
    "                row, col = get_image_details(img)\n",
    "                if row > first_valid_row and col == 1:\n",
    "                    new_first_end = row\n",
    "                    break\n",
    "\n",
    "            # Update the subgroups\n",
    "            first_subgroup = (first_valid_row, new_first_end)\n",
    "            second_subgroup = (new_first_end, first_subgroup_end)\n",
    "            subgroups[0] = first_subgroup\n",
    "            subgroups.insert(1, second_subgroup)\n",
    "    \n",
    "    return subgroups\n",
    "\n",
    "# Example use\n",
    "# subgroups = [(1, 9), (10, 17), (18, 24), (25, 30), (31, 35)]\n",
    "updated_subgroups = process_subgroups(\"Analysis/multiple_page/temp\", subgroup_ranges)\n",
    "\n",
    "for start, end in updated_subgroups:\n",
    "    print(f\"Updated Subgroup range: [{start}, {end}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section Identification\n",
    "- Identifies row numbers belonging to specific sections:\n",
    "  - **Kann Swar**\n",
    "  - **Swar**\n",
    "  - **Lyrics**\n",
    "  - **Articulation**\n",
    "- Organizes rows into their respective sections for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulation Rows:  [4, 6, 17, 20, 21]\n",
      "Kann Swar Rows:  [15]\n",
      "Swar Rows:  [16]\n",
      "Lyrics Rows:  [18]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_image_details(filename):\n",
    "    pattern = r'(\\d+)_row(\\d+)_col(\\d+)_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        page_num = int(match.group(1))\n",
    "        row_num = int(match.group(2))\n",
    "        col_num = int(match.group(3))\n",
    "        x = int(match.group(4)) \n",
    "        y = int(match.group(5))\n",
    "        w = int(match.group(6))\n",
    "        h = int(match.group(7))\n",
    "        return (page_num, row_num, col_num, x, y, w, h)\n",
    "    return None\n",
    "\n",
    "def is_articulation(w, h):\n",
    "    return 4 < h < 9 and w > 9\n",
    "\n",
    "def classify_rows_in_subgroup(subgroup_coords):\n",
    "    articulation_rows = []\n",
    "    kann_swar_rows = []\n",
    "    swar_rows = []\n",
    "    lyrics_rows = []\n",
    "\n",
    "    # Group images by rows\n",
    "    row_groups = defaultdict(list)\n",
    "    for image, page_num, row_num, x, y, w, h in subgroup_coords:\n",
    "        row_groups[row_num].append((image, page_num, x, y, w, h))\n",
    "\n",
    "    # Check for articulation rows\n",
    "    non_articulation_rows = []\n",
    "    for row_num, images in row_groups.items():\n",
    "        if all(is_articulation(w, h) for _, _, x, y, w, h in images):\n",
    "            articulation_rows.append(row_num)\n",
    "        else:\n",
    "            non_articulation_rows.append((row_num, images))\n",
    "\n",
    "    # Sort non-articulation rows by row number\n",
    "    non_articulation_rows.sort(key=lambda item: item[0])\n",
    "    remaining_rows = len(non_articulation_rows)\n",
    "\n",
    "    # Classify remaining rows based on cases\n",
    "    if remaining_rows == 3:\n",
    "        kann_swar_rows.append(non_articulation_rows[0][0])\n",
    "        swar_rows.append(non_articulation_rows[1][0])\n",
    "        lyrics_rows.append(non_articulation_rows[2][0])\n",
    "\n",
    "    elif remaining_rows == 2:\n",
    "        row1_images = non_articulation_rows[0][1]\n",
    "        row2_images = non_articulation_rows[1][1]\n",
    "        if (abs(len(row1_images) - len(row2_images)) <= 2) or (len(row1_images) > len(row2_images)):\n",
    "            swar_rows.append(non_articulation_rows[0][0])\n",
    "            lyrics_rows.append(non_articulation_rows[1][0])\n",
    "        else:\n",
    "            kann_swar_rows.append(non_articulation_rows[0][0])\n",
    "            swar_rows.append(non_articulation_rows[1][0])\n",
    "\n",
    "    elif remaining_rows == 1:\n",
    "        swar_rows.append(non_articulation_rows[0][0])\n",
    "\n",
    "    return articulation_rows, kann_swar_rows, swar_rows, lyrics_rows\n",
    "\n",
    "def process_subgroups(output_folder, subgroup_ranges):\n",
    "    images = os.listdir(output_folder)\n",
    "    coordinates = []\n",
    "\n",
    "    # Parse image details and store them\n",
    "    for image in images:\n",
    "        details = get_image_details(image)\n",
    "        if details:\n",
    "            page_num, row_num, col_num, x, y, w, h = details\n",
    "            coordinates.append((image, page_num, row_num, x, y, w, h))\n",
    "\n",
    "    articulation_rows_all = []\n",
    "    kann_swar_rows_all = []\n",
    "    swar_rows_all = []\n",
    "    lyrics_rows_all = []\n",
    "\n",
    "    # Process each subgroup range\n",
    "    for start_row, end_row in subgroup_ranges:\n",
    "        subgroup_coords = [\n",
    "            (image, page_num, row_num, x, y, w, h) for image, page_num, row_num, x, y, w, h in coordinates\n",
    "            if start_row <= row_num <= end_row\n",
    "        ]\n",
    "\n",
    "        # Classify rows within the subgroup\n",
    "        articulation_rows, kann_swar_rows, swar_rows, lyrics_rows = classify_rows_in_subgroup(subgroup_coords)\n",
    "\n",
    "        # Add rows to the respective lists\n",
    "        articulation_rows_all.extend(articulation_rows)\n",
    "        kann_swar_rows_all.extend(kann_swar_rows)\n",
    "        swar_rows_all.extend(swar_rows)\n",
    "        lyrics_rows_all.extend(lyrics_rows)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Articulation Rows: \", articulation_rows_all)\n",
    "    print(\"Kann Swar Rows: \", kann_swar_rows_all)\n",
    "    print(\"Swar Rows: \", swar_rows_all)\n",
    "    print(\"Lyrics Rows: \", lyrics_rows_all)\n",
    "\n",
    "    return {\n",
    "        \"articulation\": articulation_rows_all,\n",
    "        \"kann_swar\": kann_swar_rows_all,\n",
    "        \"swar\": swar_rows_all,\n",
    "        \"lyrics\": lyrics_rows_all\n",
    "    }\n",
    "\n",
    "    # return articulation_rows_all, kann_swar_rows_all, swar_rows_all, lyrics_rows_all\n",
    "\n",
    "# Folder where the images are stored\n",
    "output_folder = \"Analysis/multiple_page\"\n",
    "\n",
    "# Process the subgroups and classify rows\n",
    "# articulation_rows, kann_swar_rows, swar_rows, lyrics_rows = process_subgroups(output_folder, updated_subgroups)\n",
    "row_categories = process_subgroups(output_folder, updated_subgroups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_row_categories(row_categories, filename=\"row_categories.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(row_categories, f, indent=4)\n",
    "\n",
    "def load_row_categories(filename=\"row_categories.json\"):\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None  # Handle case when no file exists yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_row_categories(row_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Correction and Selection\n",
    "- Allows user to **correct** identified sections (**Kann Swar**, **Swar**, **Lyrics**, **Articulation**).\n",
    "- Enables selection of **Sthayee** and **Antara** rows.\n",
    "- Ensures accurate grouping and processing of rows based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articulation_rows = [29, 31, 35, 37, 49, 51, 55, 57, 61, 64, 68, 70]\n",
    "# kann_swar_rows = [27, 33, 40, 47, 53, 59, 66]\n",
    "# swar_rows = [28, 34, 41, 48, 54, 60, 67]\n",
    "# lyrics_rows = [30, 36, 43, 50, 56, 62, 69]\n",
    "\n",
    "row_categories = {\n",
    "    \"articulation\": [29, 31, 35, 37, 49, 51, 55, 57, 61, 64, 68, 70],\n",
    "    \"kann_swar\": [27, 33, 40, 47, 53, 59, 66],\n",
    "    \"swar\": [28, 34, 41, 48, 54, 60, 67],\n",
    "    \"lyrics\": [30, 36, 43, 50, 56, 62, 69],\n",
    "    \"sthayee\": 25,\n",
    "    \"antara\": 46\n",
    "}\n",
    "\n",
    "# sthayee = 25\n",
    "# antara = 46\n",
    "\n",
    "# articulation_rows = [4, 6, 11, 13, 17, 20, 21]\n",
    "# kann_swar_rows = [2, 15]\n",
    "# swar_rows = [3, 10, 16]\n",
    "# lyrics_rows = [5, 12, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_row_categories(row_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulation Rows:  [29, 31, 35, 37, 49, 51, 55, 57, 61, 64, 68, 70]\n",
      "Kann Swar Rows:  [27, 33, 40, 47, 53, 59, 66]\n",
      "Swar Rows:  [28, 34, 41, 48, 54, 60, 67]\n",
      "Lyrics Rows:  [30, 36, 43, 50, 56, 62, 69]\n"
     ]
    }
   ],
   "source": [
    "row_categories = load_row_categories()\n",
    "\n",
    "# Extract specific row categories\n",
    "articulation_rows = row_categories.get(\"articulation\", [])\n",
    "kann_swar_rows = row_categories.get(\"kann_swar\", [])\n",
    "swar_rows = row_categories.get(\"swar\", [])\n",
    "lyrics_rows = row_categories.get(\"lyrics\", [])\n",
    "\n",
    "# Print the results\n",
    "print(\"Articulation Rows: \", articulation_rows)\n",
    "print(\"Kann Swar Rows: \", kann_swar_rows)\n",
    "print(\"Swar Rows: \", swar_rows)\n",
    "print(\"Lyrics Rows: \", lyrics_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Taal: Dhamaar\n",
      "Total number of beats: 14\n"
     ]
    }
   ],
   "source": [
    "# Define the beat count (size of the lists) from taal information\n",
    "beat_count = taal_info[taal_name][\"beat_count\"]\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nTaal: {taal_name}\")\n",
    "print(f\"Total number of beats: {beat_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial List Creation and Mapping\n",
    "- Creates lists for each subgroup:\n",
    "  - **Kann Swar**\n",
    "  - **Swar**\n",
    "  - **Swar Articulation Checks**\n",
    "  - **Lyrics**\n",
    "  - **Lyrics Articulation Checks**\n",
    "- Stores image file paths in the respective lists.\n",
    "\n",
    "#### Kann Swar and Swar Mapping\n",
    "- **Case 1: Explicit Kann Swar Row**  \n",
    "  - Maps **Kann Swar** to its corresponding **Swar** directly.\n",
    "- **Case 2: Hidden Kann Swar in Swar Row**  \n",
    "  - Identifies **Kann Swar** images present in the **Swar** row and moves them to the **Kann Swar** list.\n",
    "  - Detects and segments composite images containing both **Kann Swar** and **Swar**.\n",
    "  - Stores the segmented **Kann Swar** image path in the **Kann Swar** list.\n",
    "  - Stores the segmented **Swar** image path in the **Swar** list.\n",
    "\n",
    "#### Articulation Mapping\n",
    "- Maps **Swar Articulation** rows to their corresponding **Swar**.\n",
    "- Maps **Lyrics Articulation** rows to their corresponding **Lyrics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup Range: (1, 6)\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row2_col1_x87_y108_w10_h13.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col5_x199_y111_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col16_x415_y105_w7_h15.png'], [], ['Analysis\\\\multiple_page\\\\0_row2_col18_x458_y106_w5_h11.png'], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row3_col1_x93_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col2_x118_y134_w10_h4.png'], ['Analysis\\\\multiple_page\\\\0_row3_col3_x146_y128_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col4_x169_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col6_x205_y125_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row3_col7_x228_y133_w11_h5.png'], ['Analysis\\\\multiple_page\\\\0_row3_col8_x252_y123_w11_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col10_x275_y129_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col11_x303_y128_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col12_x324_y121_w7_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col14_x338_y122_w43_h14.png'], ['Analysis\\\\multiple_page\\\\0_row3_col15_x388_y127_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col16_x417_y128_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col17_x439_y121_w8_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col18_x460_y121_w21_h25.png'], ['Analysis\\\\multiple_page\\\\0_row3_col20_x495_y127_w16_h12.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row5_col1_x92_y162_w13_h16.png'], ['Analysis\\\\multiple_page\\\\0_row5_col2_x122_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col3_x147_y162_w8_h11.png'], ['Analysis\\\\multiple_page\\\\0_row5_col4_x168_y162_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col6_x205_y161_w15_h14.png', 'Analysis\\\\multiple_page\\\\0_row5_col6_x208_y154_w6_h5.png'], ['Analysis\\\\multiple_page\\\\0_row5_col7_x232_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col8_x252_y162_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col10_x274_y162_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col11_x303_y161_w12_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col12_x323_y161_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row5_col14_x348_y156_w27_h13.png'], ['Analysis\\\\multiple_page\\\\0_row5_col15_x388_y160_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col16_x418_y161_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col17_x438_y154_w9_h18.png'], ['Analysis\\\\multiple_page\\\\0_row5_col18_x459_y160_w14_h9.png'], ['Analysis\\\\multiple_page\\\\0_row5_col19_x477_y159_w6_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col20_x497_y161_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col21_x514_y161_w5_h13.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 13)\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row10_col1_x87_y297_w32_h7.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col9_x299_y288_w14_h15.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col13_x411_y289_w14_h15.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y294_w31_h10_upper.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row10_col1_x86_y312_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row10_col2_x108_y312_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row10_col3_x131_y312_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row10_col4_x152_y311_w17_h10.png'], ['Analysis\\\\multiple_page\\\\0_row10_col5_x190_y308_w17_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col6_x220_y316_w9_h4.png'], ['Analysis\\\\multiple_page\\\\0_row10_col7_x240_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col8_x266_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col9_x301_y308_w17_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col10_x326_y306_w24_h14.png'], ['Analysis\\\\multiple_page\\\\0_row10_col11_x364_y306_w8_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col12_x385_y307_w11_h17.png'], ['Analysis\\\\multiple_page\\\\0_row10_col13_x413_y308_w16_h16.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y307_w31_h14_lower.png'], ['Analysis\\\\multiple_page\\\\0_row10_col15_x471_y312_w15_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col16_x489_y312_w5_h15.png'], ['Analysis\\\\multiple_page\\\\0_row10_col17_x503_y317_w9_h4.png']]\n",
      "Swar Articulation Checks: [False, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row12_col1_x87_y342_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col2_x110_y342_w9_h15.png'], ['Analysis\\\\multiple_page\\\\0_row12_col3_x132_y337_w10_h18.png'], ['Analysis\\\\multiple_page\\\\0_row12_col4_x153_y341_w15_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col5_x189_y342_w17_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col6_x220_y342_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col7_x245_y342_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col8_x268_y342_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col9_x304_y337_w14_h21.png'], ['Analysis\\\\multiple_page\\\\0_row12_col10_x329_y342_w15_h11.png'], ['Analysis\\\\multiple_page\\\\0_row12_col11_x362_y343_w17_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col12_x388_y343_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col13_x415_y342_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col14_x439_y342_w15_h11.png'], ['Analysis\\\\multiple_page\\\\0_row12_col15_x471_y343_w15_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col17_x501_y343_w8_h12.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (15, 21)\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row15_col1_x84_y378_w11_h13.png'], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col4_x155_y377_w10_h14.png'], ['Analysis\\\\multiple_page\\\\0_row15_col5_x188_y381_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col13_x413_y377_w6_h14.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row16_col1_x86_y399_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row16_col2_x112_y404_w10_h3.png'], ['Analysis\\\\multiple_page\\\\0_row16_col3_x135_y398_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col4_x161_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col5_x190_y395_w10_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col6_x212_y403_w12_h4.png'], ['Analysis\\\\multiple_page\\\\0_row16_col7_x243_y396_w11_h16.png'], ['Analysis\\\\multiple_page\\\\0_row16_col8_x272_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col9_x302_y399_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col10_x321_y392_w9_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col11_x337_y394_w43_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col12_x386_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col13_x415_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col14_x437_y392_w8_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col15_x458_y393_w20_h24.png'], ['Analysis\\\\multiple_page\\\\0_row16_col17_x491_y398_w17_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row18_col1_x86_y428_w16_h17.png'], ['Analysis\\\\multiple_page\\\\0_row18_col2_x112_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col3_x134_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col4_x159_y432_w11_h9.png'], ['Analysis\\\\multiple_page\\\\0_row18_col5_x190_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col6_x215_y432_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col7_x245_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col8_x270_y433_w13_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col9_x303_y433_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row18_col10_x322_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col11_x340_y426_w14_h15.png', 'Analysis\\\\multiple_page\\\\0_row18_col11_x357_y431_w22_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col12_x388_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col13_x415_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col14_x436_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col15_x457_y431_w12_h10.png'], ['Analysis\\\\multiple_page\\\\0_row18_col16_x473_y431_w7_h11.png'], ['Analysis\\\\multiple_page\\\\0_row18_col17_x492_y432_w10_h13.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# storing image paths in lists for direct access\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from save_and_load import save_lists_in_subgroups, load_lists_in_subgroups\n",
    "\n",
    "# Define the path to the folder containing the images\n",
    "image_folder_path = 'Analysis/multiple_page'\n",
    "\n",
    "# store the final updated subgroup to use further\n",
    "subgroup_ranges = updated_subgroups\n",
    "\n",
    "# Function to extract information from the image filename\n",
    "def extract_info_from_filename(filename, image_folder_path):\n",
    "    pattern = r'(\\d+)_row(\\d+)(?:_col(\\d+))?_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        page_num = int(match.group(1))\n",
    "        row_num = int(match.group(2))\n",
    "        col_num = int(match.group(3)) if match.group(3) else None\n",
    "        x = int(match.group(4))\n",
    "        y = int(match.group(5))\n",
    "        width = int(match.group(6))\n",
    "        height = int(match.group(7))\n",
    "        # Use os.path.join to handle path separators correctly\n",
    "        image_path = os.path.normpath(os.path.join(image_folder_path, filename))\n",
    "        return page_num, row_num, col_num, x, y, width, height, image_path\n",
    "    return None\n",
    "\n",
    "# Load all image filenames and extract their information\n",
    "image_files = os.listdir(image_folder_path)\n",
    "image_info = [extract_info_from_filename(f, image_folder_path) for f in image_files]\n",
    "image_info = [info for info in image_info if info is not None]\n",
    "\n",
    "# Organize images by row and column\n",
    "row_col_images = defaultdict(lambda: defaultdict(list))\n",
    "for info in image_info:\n",
    "    page_num, row_num, col_num, x, y, width, height, image_path = info\n",
    "    row_col_images[row_num][col_num].append((x, y, width, height, image_path))\n",
    "\n",
    "# Function to pad lists to match the beat count\n",
    "def pad_lists(lists, size):\n",
    "    if len(lists) < size:\n",
    "        padding = [[] for _ in range(size - len(lists))]\n",
    "        return padding + lists\n",
    "    return lists\n",
    "\n",
    "def save_segment(segment, subgroup_range, col, part_type, original_filename):\n",
    "    \"\"\"\n",
    "    Function to save a segmented part and return its path.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment: The segmented image (enlarged by a factor of 3).\n",
    "    - subgroup_range: The subgroup range.\n",
    "    - col: The column number.\n",
    "    - part_type: Type of segment ('upper' or 'lower').\n",
    "    - original_filename: The original filename of the image before segmentation.\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the saved segment.\n",
    "    \"\"\"\n",
    "    # Extract original image details from the filename\n",
    "    pattern = r'(\\d+)_row(\\d+)_col(\\d+)_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, original_filename)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Original filename {original_filename} does not match the expected pattern.\")\n",
    "    \n",
    "    page_num = match.group(1)\n",
    "    row_num = match.group(2)\n",
    "    col_num = match.group(3)\n",
    "    original_x = int(match.group(4))  # x-coordinate (pre-enlarged)\n",
    "    original_y = int(match.group(5))  # y-coordinate (pre-enlarged)\n",
    "    original_w = int(match.group(6))  # width (pre-enlarged)\n",
    "    original_h = int(match.group(7))  # height (pre-enlarged)\n",
    "    \n",
    "    # Calculate new coordinates for the segmented part (scaled down by a factor of 3)\n",
    "    if part_type == 'upper':\n",
    "        # Upper part: y remains the same, height is the separation row\n",
    "        new_x = original_x\n",
    "        new_y = original_y\n",
    "        new_w = original_w\n",
    "        new_h = segment.shape[0] // 3  # Height of the upper part (scaled down)\n",
    "    elif part_type == 'lower':\n",
    "        # Lower part: y is original_y + height of the upper part, height is adjusted\n",
    "        new_x = original_x\n",
    "        new_y = original_y + (original_h - (segment.shape[0] // 3))  # Adjust y for lower part (scaled down)\n",
    "        new_w = original_w\n",
    "        new_h = segment.shape[0] // 3  # Height of the lower part (scaled down)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid part_type. Must be 'upper' or 'lower'.\")\n",
    "    \n",
    "    # Create the new filename\n",
    "    new_filename = f\"{page_num}_row{row_num}_col{col_num}_x{new_x}_y{new_y}_w{new_w}_h{new_h}_{part_type}.png\"\n",
    "    \n",
    "    # Save the segmented image\n",
    "    output_folder = os.path.normpath('Analysis/multiple_page_segmented')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    segment_path = os.path.join(output_folder, new_filename)\n",
    "    cv2.imwrite(segment_path, segment)\n",
    "    \n",
    "    return segment_path\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "    return thresh\n",
    "\n",
    "# Function to check articulation in an image\n",
    "def check_articulation(image):\n",
    "    processed_image = preprocess_image(image)\n",
    "    contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < h < 21 and w > 25:\n",
    "            upper_part = image[:y, :]\n",
    "            if upper_part.shape[0] > 0:\n",
    "                return True  # Return true if there is articulation\n",
    "            break\n",
    "    \n",
    "    return False  # Return false if there is no articulation\n",
    "\n",
    "def process_outlier_image(img, subgroup_range, col):\n",
    "    \"\"\"Process a single outlier image to separate kann swar and swar parts.\"\"\"\n",
    "    x, y, w, h, image_path = img\n",
    "    \n",
    "    # Load and check articulation\n",
    "    outlier_image = cv2.imread(image_path)\n",
    "    is_articulated = check_articulation(outlier_image)\n",
    "    \n",
    "    if is_articulated:\n",
    "        return [image_path], []  # swar_list, kann_swar_list\n",
    "    \n",
    "    # Process image to find separation\n",
    "    gray = cv2.cvtColor(outlier_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                 cv2.THRESH_BINARY_INV, 21, 5)\n",
    "    \n",
    "    # Morphological operations\n",
    "    closing_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, closing_kernel)\n",
    "    \n",
    "    # Find separation line\n",
    "    separation_row = find_separation_line(closed, outlier_image.shape[0])\n",
    "    \n",
    "    # Split and crop parts\n",
    "    upper_part, lower_part = split_image(outlier_image, separation_row)\n",
    "    upper_part_cropped = crop_white_background(upper_part)\n",
    "    lower_part_cropped = crop_white_background(lower_part)\n",
    "    \n",
    "    # Save segments\n",
    "    original_filename = os.path.basename(image_path)\n",
    "    upper_part_path = save_segment(upper_part_cropped, subgroup_range, col, 'upper', original_filename)\n",
    "    lower_part_path = save_segment(lower_part_cropped, subgroup_range, col, 'lower', original_filename)\n",
    "    \n",
    "    return [lower_part_path], [upper_part_path]  # swar_list, kann_swar_list\n",
    "\n",
    "def find_separation_line(binary_image, image_height):\n",
    "    \"\"\"Find the optimal separation line in a binary image.\"\"\"\n",
    "    vertical_projection = np.sum(binary_image, axis=1) / 255\n",
    "    lower_bound = int(image_height * 0.3)\n",
    "    upper_bound = int(image_height * 0.5)\n",
    "    \n",
    "    valid_range = vertical_projection[lower_bound:upper_bound]\n",
    "    if valid_range.size > 0:\n",
    "        separation_row_in_range = np.argmin(valid_range)\n",
    "        return lower_bound + separation_row_in_range\n",
    "    return image_height // 2  # Default to middle\n",
    "\n",
    "def split_image(image, separation_row):\n",
    "    \"\"\"Split image into upper and lower parts at separation_row.\"\"\"\n",
    "    return image[:separation_row, :], image[separation_row:, :]\n",
    "\n",
    "def crop_white_background(image):\n",
    "    \"\"\"Crop white background from an image.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "    \n",
    "    if len(coords) > 0:\n",
    "        y1, x1 = coords.min(axis=0)\n",
    "        y2, x2 = coords.max(axis=0)\n",
    "        return image[y1:y2 + 1, x1:x2 + 1]\n",
    "    return image\n",
    "\n",
    "def process_non_outlier_images(non_outlier_images):\n",
    "    \"\"\"Process non-outlier images to identify hidden kann swars.\"\"\"\n",
    "    if len(non_outlier_images) == 1:\n",
    "        return [non_outlier_images[0][4]], []  # swar_list, kann_swar_list\n",
    "    \n",
    "    # Multiple images - sort by y-value\n",
    "    sorted_images = sorted(non_outlier_images, key=lambda x: x[1])\n",
    "    return [sorted_images[1][4]], [sorted_images[0][4]]  # swar_list, kann_swar_list\n",
    "\n",
    "# Function to process a subgroup and create the lists of lists\n",
    "def process_subgroup(subgroup_range, is_first_subgroup):\n",
    "    start_row, end_row = subgroup_range\n",
    "    \n",
    "    # Find the swar row in this subgroup\n",
    "    swar_row = None\n",
    "    for row in swar_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            swar_row = row\n",
    "            break\n",
    "    \n",
    "    if not swar_row:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # Find the kann swar row in this subgroup\n",
    "    kann_swar_row = None\n",
    "    for row in kann_swar_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            kann_swar_row = row\n",
    "            break\n",
    "    \n",
    "    # Find the articulation rows in this subgroup\n",
    "    articulation_rows_in_subgroup = [row for row in articulation_rows if start_row <= row <= end_row]\n",
    "    \n",
    "    # Find the lyrics row in this subgroup\n",
    "    lyrics_row = None\n",
    "    for row in lyrics_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            lyrics_row = row\n",
    "            break\n",
    "    \n",
    "    # Get the swar images and their column numbers\n",
    "    swar_images = row_col_images[swar_row]\n",
    "    swar_cols = sorted(swar_images.keys())\n",
    "    \n",
    "    # Get the kann swar images and their column numbers (if kann swar row exists)\n",
    "    kann_swar_images = row_col_images[kann_swar_row] if kann_swar_row else {}\n",
    "    kann_swar_cols = sorted(kann_swar_images.keys())\n",
    "    \n",
    "    # Get the lyrics images (if lyrics row exists)\n",
    "    lyrics_images = row_col_images[lyrics_row] if lyrics_row else {}\n",
    "    lyrics_cols = sorted(lyrics_images.keys()) if lyrics_row else []\n",
    "    \n",
    "    # Create the lists of lists\n",
    "    swar_list = []\n",
    "    kann_swar_list = []\n",
    "    swar_articulation_checks = [False] * len(swar_cols)\n",
    "    lyrics_articulation_checks = [False] * len(lyrics_cols)\n",
    "    lyrics_list = []\n",
    "    \n",
    "    # Case 1: If there is an explicit kann swar row\n",
    "    if kann_swar_row:\n",
    "        swar_index = 0\n",
    "        kann_swar_index = 0\n",
    "        \n",
    "        while swar_index < len(swar_cols) or kann_swar_index < len(kann_swar_cols):\n",
    "            swar_col = swar_cols[swar_index] if swar_index < len(swar_cols) else None\n",
    "            kann_swar_col = kann_swar_cols[kann_swar_index] if kann_swar_index < len(kann_swar_cols) else None\n",
    "            \n",
    "            # If both columns exist and match\n",
    "            if swar_col is not None and kann_swar_col is not None and swar_col == kann_swar_col:\n",
    "                swar_list.append([x[4] for x in swar_images[swar_col]])  # Store image paths\n",
    "                kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                swar_index += 1\n",
    "                kann_swar_index += 1\n",
    "            # If swar column exists but kann swar column doesn't match or is missing\n",
    "            elif swar_col is not None and (kann_swar_col is None or swar_col < kann_swar_col):\n",
    "                swar_list.append([x[4] for x in swar_images[swar_col]])  # Store image paths\n",
    "                kann_swar_list.append([])\n",
    "                swar_index += 1\n",
    "            # If kann swar column exists but swar column doesn't match or is missing\n",
    "            elif kann_swar_col is not None and (swar_col is None or kann_swar_col < swar_col):\n",
    "                # Assign the kann swar to the next available swar column\n",
    "                if swar_index < len(swar_cols):\n",
    "                    swar_list.append([x[4] for x in swar_images[swar_cols[swar_index]]])  # Store image paths\n",
    "                    kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                    swar_index += 1\n",
    "                    kann_swar_index += 1\n",
    "                else:\n",
    "                    # If no more swar columns are available, append an empty list\n",
    "                    swar_list.append([])\n",
    "                    kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                    kann_swar_index += 1\n",
    "    \n",
    "    # Case 2: If there is no explicit kann swar row, check for hidden kann swars in the swar row\n",
    "    else:\n",
    "        for col in swar_cols:\n",
    "            images_in_col = swar_images[col]\n",
    "            \n",
    "            # Separate outliers\n",
    "            outlier_images = [img for img in images_in_col if img[3] > 25]\n",
    "            non_outlier_images = [img for img in images_in_col if img[3] <= 25]\n",
    "            \n",
    "            # Process outliers\n",
    "            for img in outlier_images:\n",
    "                swar, kann_swar = process_outlier_image(img, subgroup_range, col)\n",
    "                swar_list.append(swar)\n",
    "                kann_swar_list.append(kann_swar)\n",
    "            \n",
    "            # Process non-outliers\n",
    "            if non_outlier_images:\n",
    "                swar, kann_swar = process_non_outlier_images(non_outlier_images)\n",
    "                swar_list.append(swar)\n",
    "                kann_swar_list.append(kann_swar)\n",
    "    \n",
    "    # Handle articulation rows\n",
    "    for articulation_row in articulation_rows_in_subgroup:\n",
    "        # Find the row just before the articulation row\n",
    "        prev_row = articulation_row - 1\n",
    "        if prev_row in swar_rows:\n",
    "            # Swar articulation\n",
    "            articulation_images = row_col_images[articulation_row]\n",
    "            articulation_cols = sorted(articulation_images.keys())\n",
    "            for i, col in enumerate(swar_cols):\n",
    "                if col in articulation_cols:\n",
    "                    swar_articulation_checks[i] = True\n",
    "        elif prev_row in lyrics_rows:\n",
    "            # Lyrics articulation\n",
    "            articulation_images = row_col_images[articulation_row]\n",
    "            articulation_cols = sorted(articulation_images.keys())\n",
    "            for i, col in enumerate(lyrics_cols):\n",
    "                if col in articulation_cols:\n",
    "                    lyrics_articulation_checks[i] = True\n",
    "    \n",
    "    # Handle lyrics row (append images one by one without comparing column numbers)\n",
    "    if lyrics_row:\n",
    "        # Get all lyrics images in order\n",
    "        lyrics_cols = sorted(lyrics_images.keys())\n",
    "        for col in lyrics_cols:\n",
    "            lyrics_list.append([x[4] for x in lyrics_images[col]])  # Store image paths\n",
    "    else:\n",
    "        lyrics_list = [[] for _ in range(len(swar_cols))]\n",
    "    \n",
    "    # Pad lists to match the beat count\n",
    "    if is_first_subgroup:\n",
    "        swar_list = pad_lists(swar_list, beat_count)\n",
    "        kann_swar_list = pad_lists(kann_swar_list, beat_count)\n",
    "        swar_articulation_checks = pad_lists(swar_articulation_checks, beat_count)\n",
    "        lyrics_articulation_checks = pad_lists(lyrics_articulation_checks, beat_count)\n",
    "        lyrics_list = pad_lists(lyrics_list, beat_count)\n",
    "    else:\n",
    "        if len(swar_list) < beat_count:\n",
    "            swar_list += [[] for _ in range(beat_count - len(swar_list))]\n",
    "        if len(kann_swar_list) < beat_count:\n",
    "            kann_swar_list += [[] for _ in range(beat_count - len(kann_swar_list))]\n",
    "        if len(swar_articulation_checks) < beat_count:\n",
    "            swar_articulation_checks += [False for _ in range(beat_count - len(swar_articulation_checks))]\n",
    "        if len(lyrics_articulation_checks) < beat_count:\n",
    "            lyrics_articulation_checks += [False for _ in range(beat_count - len(lyrics_articulation_checks))]\n",
    "        if len(lyrics_list) < beat_count:\n",
    "            lyrics_list += [[] for _ in range(beat_count - len(lyrics_list))]\n",
    "    \n",
    "    return swar_list, kann_swar_list, swar_articulation_checks, lyrics_articulation_checks, lyrics_list\n",
    "\n",
    "def generate_lists_in_subgroups(subgroup_ranges):\n",
    "    \"\"\"\n",
    "    Process all subgroups and return a dictionary of results.\n",
    "\n",
    "    Args:\n",
    "        subgroup_ranges (list): A list of tuples where each tuple represents (start_row, end_row).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing processed results for each subgroup.\n",
    "    \"\"\"\n",
    "    subgroup_results = {}\n",
    "\n",
    "    for i, subgroup_range in enumerate(subgroup_ranges):\n",
    "        is_first_subgroup = (i == 0)\n",
    "        \n",
    "        # Call process_subgroup for each subgroup\n",
    "        swar_list, kann_swar_list, swar_articulation_checks, lyrics_articulation_checks, lyrics_list = process_subgroup(subgroup_range, is_first_subgroup)\n",
    "        \n",
    "        if swar_list and kann_swar_list:\n",
    "            subgroup_results[subgroup_range] = {\n",
    "                'swar_list': swar_list,\n",
    "                'kann_swar_list': kann_swar_list,\n",
    "                'swar_articulation_checks': swar_articulation_checks,\n",
    "                'lyrics_articulation_checks': lyrics_articulation_checks,\n",
    "                'lyrics_list': lyrics_list\n",
    "            }\n",
    "    \n",
    "    return subgroup_results\n",
    "\n",
    "subgroup_results = generate_lists_in_subgroups(subgroup_ranges)\n",
    "\n",
    "save_lists_in_subgroups(subgroup_results)\n",
    "\n",
    "\n",
    "subgroups = load_lists_in_subgroups()\n",
    "\n",
    "# Print the results for each subgroup\n",
    "for subgroup_range, results in subgroups.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Kann Swar List: {results['kann_swar_list']}\")\n",
    "    print(f\"Swar List: {results['swar_list']}\")\n",
    "    print(f\"Swar Articulation Checks: {results['swar_articulation_checks']}\")\n",
    "    print(f\"Lyrics List: {results['lyrics_list']}\")\n",
    "    print(f\"Lyrics Articulation Checks: {results['lyrics_articulation_checks']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meend Segmentation and List Creation\n",
    "- Segments composite **Meend** and **Kann Swar** images.\n",
    "- Stores the **Kann Swar** image in its correct position in the **Kann Swar List** based on coordinates.\n",
    "- Creates a separate **Meend List** to store:\n",
    "  - **Start** and **end positions** of each **Meend** corresponding to the **Swar** row.\n",
    "- Detects **Meend** in the **Kann Swar** row.\n",
    "- If **Meend** is present:\n",
    "    - Update the **Meend List**\n",
    "    - Remove the image path from **Kann Swar List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup Range: (1, 6)\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row2_col1_x87_y108_w10_h13.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col5_x199_y111_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col16_x415_y105_w7_h15.png'], [], ['Analysis\\\\multiple_page\\\\0_row2_col18_x458_y106_w5_h11.png'], []]\n",
      "Meend List: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row3_col1_x93_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col2_x118_y134_w10_h4.png'], ['Analysis\\\\multiple_page\\\\0_row3_col3_x146_y128_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col4_x169_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col6_x205_y125_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row3_col7_x228_y133_w11_h5.png'], ['Analysis\\\\multiple_page\\\\0_row3_col8_x252_y123_w11_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col10_x275_y129_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col11_x303_y128_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col12_x324_y121_w7_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col14_x338_y122_w43_h14.png'], ['Analysis\\\\multiple_page\\\\0_row3_col15_x388_y127_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col16_x417_y128_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col17_x439_y121_w8_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col18_x460_y121_w21_h25.png'], ['Analysis\\\\multiple_page\\\\0_row3_col20_x495_y127_w16_h12.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row5_col1_x92_y162_w13_h16.png'], ['Analysis\\\\multiple_page\\\\0_row5_col2_x122_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col3_x147_y162_w8_h11.png'], ['Analysis\\\\multiple_page\\\\0_row5_col4_x168_y162_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col6_x205_y161_w15_h14.png', 'Analysis\\\\multiple_page\\\\0_row5_col6_x208_y154_w6_h5.png'], ['Analysis\\\\multiple_page\\\\0_row5_col7_x232_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col8_x252_y162_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col10_x274_y162_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col11_x303_y161_w12_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col12_x323_y161_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row5_col14_x348_y156_w27_h13.png'], ['Analysis\\\\multiple_page\\\\0_row5_col15_x388_y160_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col16_x418_y161_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col17_x438_y154_w9_h18.png'], ['Analysis\\\\multiple_page\\\\0_row5_col18_x459_y160_w14_h9.png'], ['Analysis\\\\multiple_page\\\\0_row5_col19_x477_y159_w6_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col20_x497_y161_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col21_x514_y161_w5_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 13)\n",
      "Kann Swar List: [[], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col9_x299_y288_w14_h15.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col13_x411_y289_w14_h15.png'], [], [], [], []]\n",
      "Meend List: ['S', 'E', '', '', '', '', '', '', '', '', '', '', '', 'E', '', '', '']\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row10_col1_x86_y312_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row10_col2_x108_y312_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row10_col3_x131_y312_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row10_col4_x152_y311_w17_h10.png'], ['Analysis\\\\multiple_page\\\\0_row10_col5_x190_y308_w17_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col6_x220_y316_w9_h4.png'], ['Analysis\\\\multiple_page\\\\0_row10_col7_x240_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col8_x266_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col9_x301_y308_w17_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col10_x326_y306_w24_h14.png'], ['Analysis\\\\multiple_page\\\\0_row10_col11_x364_y306_w8_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col12_x385_y307_w11_h17.png'], ['Analysis\\\\multiple_page\\\\0_row10_col13_x413_y308_w16_h16.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y307_w31_h14_lower.png'], ['Analysis\\\\multiple_page\\\\0_row10_col15_x471_y312_w15_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col16_x489_y312_w5_h15.png'], ['Analysis\\\\multiple_page\\\\0_row10_col17_x503_y317_w9_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row12_col1_x87_y342_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col2_x110_y342_w9_h15.png'], ['Analysis\\\\multiple_page\\\\0_row12_col3_x132_y337_w10_h18.png'], ['Analysis\\\\multiple_page\\\\0_row12_col4_x153_y341_w15_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col5_x189_y342_w17_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col6_x220_y342_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col7_x245_y342_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col8_x268_y342_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col9_x304_y337_w14_h21.png'], ['Analysis\\\\multiple_page\\\\0_row12_col10_x329_y342_w15_h11.png'], ['Analysis\\\\multiple_page\\\\0_row12_col11_x362_y343_w17_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col12_x388_y343_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col13_x415_y342_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col14_x439_y342_w15_h11.png'], ['Analysis\\\\multiple_page\\\\0_row12_col15_x471_y343_w15_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col17_x501_y343_w8_h12.png']]\n",
      "Swar Articulation Checks: [False, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (15, 21)\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row15_col1_x84_y378_w11_h13.png'], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col4_x155_y377_w10_h14.png'], ['Analysis\\\\multiple_page\\\\0_row15_col5_x188_y381_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col13_x413_y377_w6_h14.png'], [], [], []]\n",
      "Meend List: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row16_col1_x86_y399_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row16_col2_x112_y404_w10_h3.png'], ['Analysis\\\\multiple_page\\\\0_row16_col3_x135_y398_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col4_x161_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col5_x190_y395_w10_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col6_x212_y403_w12_h4.png'], ['Analysis\\\\multiple_page\\\\0_row16_col7_x243_y396_w11_h16.png'], ['Analysis\\\\multiple_page\\\\0_row16_col8_x272_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col9_x302_y399_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col10_x321_y392_w9_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col11_x337_y394_w43_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col12_x386_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col13_x415_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col14_x437_y392_w8_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col15_x458_y393_w20_h24.png'], ['Analysis\\\\multiple_page\\\\0_row16_col17_x491_y398_w17_h13.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row18_col1_x86_y428_w16_h17.png'], ['Analysis\\\\multiple_page\\\\0_row18_col2_x112_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col3_x134_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col4_x159_y432_w11_h9.png'], ['Analysis\\\\multiple_page\\\\0_row18_col5_x190_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col6_x215_y432_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col7_x245_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col8_x270_y433_w13_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col9_x303_y433_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row18_col10_x322_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col11_x340_y426_w14_h15.png', 'Analysis\\\\multiple_page\\\\0_row18_col11_x357_y431_w22_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col12_x388_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col13_x415_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col14_x436_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col15_x457_y431_w12_h10.png'], ['Analysis\\\\multiple_page\\\\0_row18_col16_x473_y431_w7_h11.png'], ['Analysis\\\\multiple_page\\\\0_row18_col17_x492_y432_w10_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Adaptive thresholding on grayscale image\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "    return thresh\n",
    "\n",
    "# Function to save segmented parts\n",
    "def save_segment(segment, subgroup_range, index, part_type):\n",
    "    \"\"\"\n",
    "    Function to save a segmented part and return its path.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment: The segmented image.\n",
    "    - subgroup_range: The subgroup range.\n",
    "    - index: The index in the list.\n",
    "    - part_type: Type of segment ('left', 'mid', 'right').\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the saved segment.\n",
    "    \"\"\"\n",
    "    output_folder = os.path.normpath('Analysis/multiple_page_segmented')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    segment_filename = f\"{subgroup_range[0]}_{subgroup_range[1]}_{index}_{part_type}.png\"\n",
    "    segment_path = os.path.join(output_folder, segment_filename)\n",
    "    cv2.imwrite(segment_path, segment)\n",
    "    \n",
    "    return segment_path\n",
    "\n",
    "# Function to extract meend and kann swar segments\n",
    "def extract_alphabets_vertical(image_path):\n",
    "    \"\"\"\n",
    "    Function to perform vertical segmentation on an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    \n",
    "    Returns:\n",
    "    - left_part: Left part of the image (kann swar or None).\n",
    "    - mid_part: Mid part of the image (meend).\n",
    "    - right_part: Right part of the image (kann swar or None).\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None, None, None\n",
    "\n",
    "    processed_image = preprocess_image(image)\n",
    "    contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    valid_coords = []\n",
    "    all_coords = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 <= h <= 25 and w > 25:\n",
    "            valid_coords.append((x, y, w, h))\n",
    "        else:\n",
    "            all_coords.append((x, y, w, h))\n",
    "\n",
    "    left_part, mid_part, right_part = None, None, None\n",
    "    \n",
    "    if valid_coords:\n",
    "        valid_coords = sorted(valid_coords, key=lambda coord: coord[0])\n",
    "        leftmost_valid = valid_coords[0]\n",
    "        rightmost_valid = valid_coords[-1]\n",
    "\n",
    "        left_cut = None\n",
    "        x1, y1, w1, h1 = leftmost_valid\n",
    "        for x, y, w, h in all_coords:\n",
    "            if x <= x1 and (y + h) >= y1 and h > 10 and w > 10:\n",
    "                left_cut = x1\n",
    "                break\n",
    "\n",
    "        right_cut = None\n",
    "        x2, y2, w2, h2 = rightmost_valid\n",
    "        for x, y, w, h in all_coords:\n",
    "            if x >= (x2 + w2) and (y + h) >= y2 and h > 10 and w > 10:\n",
    "                right_cut = x2 + w2\n",
    "                break\n",
    "\n",
    "        if left_cut is not None and right_cut is not None:\n",
    "            left_part = image[:, :left_cut]\n",
    "            mid_part = image[:, left_cut:right_cut]\n",
    "            right_part = image[:, right_cut:]\n",
    "\n",
    "        elif left_cut is not None:\n",
    "            left_part = image[:, :left_cut]\n",
    "            right_part = image[:, left_cut:]\n",
    "        \n",
    "        elif right_cut is not None:\n",
    "            left_part = image[:, :right_cut]\n",
    "            right_part = image[:, right_cut:]\n",
    "\n",
    "    # If no segmentation occurred, treat the entire image as mid_part\n",
    "    if left_part is None and right_part is None:\n",
    "        mid_part = image\n",
    "\n",
    "    return left_part, mid_part, right_part\n",
    "\n",
    "# Function to identify meend and kann swar\n",
    "def identify_meend_and_kann_swar(left_part, mid_part, right_part):\n",
    "    \"\"\"\n",
    "    Function to identify and structure meend and kann swar based on the width of the segments.\n",
    "    \n",
    "    Parameters:\n",
    "    - left_part: The left part of the image.\n",
    "    - mid_part: The mid part of the image.\n",
    "    - right_part: The right part of the image.\n",
    "    \n",
    "    Returns:\n",
    "    - left_part: The left part (kann swar or None).\n",
    "    - mid_part: The mid part (meend).\n",
    "    - right_part: The right part (kann swar or None).\n",
    "    \"\"\"\n",
    "    # Determine which part is meend based on width\n",
    "    parts = {\n",
    "        \"left\": left_part,\n",
    "        \"mid\": mid_part,\n",
    "        \"right\": right_part\n",
    "    }\n",
    "\n",
    "    # Filter out None parts\n",
    "    valid_parts = {k: v for k, v in parts.items() if v is not None}\n",
    "\n",
    "    # If no segmentation occurred (only mid_part exists)\n",
    "    if len(valid_parts) == 1 and \"mid\" in valid_parts:\n",
    "        # Treat the entire image as meend\n",
    "        left_part = None\n",
    "        right_part = None\n",
    "        mid_part = valid_parts[\"mid\"]\n",
    "    \n",
    "    # If there are only two parts, identify meend based on width\n",
    "    elif len(valid_parts) == 2:\n",
    "        # Find the part with the maximum width (meend)\n",
    "        meend_key = max(valid_parts, key=lambda k: valid_parts[k].shape[1])\n",
    "        kann_swar_key = [k for k in valid_parts.keys() if k != meend_key][0]\n",
    "\n",
    "        # Reassign parts to ensure meend is in the middle\n",
    "        if meend_key == \"left\":\n",
    "            mid_part = valid_parts[meend_key]\n",
    "            right_part = valid_parts[kann_swar_key]\n",
    "            left_part = None\n",
    "        elif meend_key == \"right\":\n",
    "            mid_part = valid_parts[meend_key]\n",
    "            left_part = valid_parts[kann_swar_key]\n",
    "            right_part = None\n",
    "        else:\n",
    "            # If meend is already in the middle, no changes needed\n",
    "            pass\n",
    "\n",
    "    # If there are three parts, meend is always in the middle\n",
    "    elif len(valid_parts) == 3:\n",
    "        mid_part = valid_parts[\"mid\"]\n",
    "        left_part = valid_parts[\"left\"]\n",
    "        right_part = valid_parts[\"right\"]\n",
    "\n",
    "    return left_part, mid_part, right_part\n",
    "\n",
    "# Function to update kann swar and meend lists\n",
    "def update_kann_swar_and_meend_lists():\n",
    "    \"\"\"\n",
    "    Function to update kann swar and meend lists based on segmentation.\n",
    "    \n",
    "    Parameters:\n",
    "    - subgroup_results: Dictionary containing subgroup results.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Load existing data from JSON\n",
    "    subgroup_results = load_lists_in_subgroups()\n",
    "    \n",
    "    if not subgroup_results:\n",
    "        print(\"No data found in JSON file\")\n",
    "        return\n",
    "\n",
    "    for subgroup_range, results in subgroup_results.items():\n",
    "        kann_swar_list = results['kann_swar_list']\n",
    "        swar_list = results['swar_list']\n",
    "        \n",
    "        # Initialize meend list with empty values\n",
    "        meend_list = ['' for _ in range(len(swar_list))]\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(kann_swar_list):\n",
    "            if kann_swar_list[i]:  # Check if the list is not empty\n",
    "                image_path = kann_swar_list[i][0]\n",
    "                # Extract width from the filename\n",
    "                filename = os.path.basename(image_path)\n",
    "                width = int(filename.split('_w')[1].split('_')[0])\n",
    "                \n",
    "                if width > 20:  # Only process if width > 20\n",
    "                    # Perform segmentation\n",
    "                    left_part, mid_part, right_part = extract_alphabets_vertical(image_path)\n",
    "                    \n",
    "                    # Identify and structure meend and kann swar\n",
    "                    left_part, mid_part, right_part = identify_meend_and_kann_swar(left_part, mid_part, right_part)\n",
    "                    \n",
    "                    if mid_part is not None:  # If meend is found\n",
    "                        # Mark start of meend\n",
    "                        meend_list[i] = 'S'\n",
    "                        \n",
    "                        # Calculate x + w for the current image\n",
    "                        x = int(filename.split('_x')[1].split('_')[0])\n",
    "                        w = width\n",
    "                        x_end = x + w\n",
    "                        \n",
    "                        # Find the end of meend\n",
    "                        j = i + 1\n",
    "                        while j < len(swar_list):\n",
    "                            swar_image_path = swar_list[j][0]\n",
    "                            swar_filename = os.path.basename(swar_image_path)\n",
    "                            swar_x = int(swar_filename.split('_x')[1].split('_')[0])\n",
    "                            \n",
    "                            if swar_x >= x_end:\n",
    "                                break  # Stop if swar_x is outside meend area\n",
    "                            j += 1\n",
    "                        \n",
    "                        # Mark end of meend\n",
    "                        if j > i:\n",
    "                            meend_list[j - 1] = 'E'\n",
    "                        \n",
    "                        # Update kann swar list based on segmentation\n",
    "                        if left_part is not None:\n",
    "                            kann_swar_list[i] = [save_segment(left_part, subgroup_range, i, 'left')]\n",
    "                        if right_part is not None:\n",
    "                            kann_swar_list[j - 1] = [save_segment(right_part, subgroup_range, j - 1, 'right')]\n",
    "                        if left_part is None and right_part is None:\n",
    "                            kann_swar_list[i] = []  # Remove the original image if no segmentation\n",
    "                        \n",
    "                        # Skip processed indices\n",
    "                        i = j\n",
    "                    else:\n",
    "                        i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Update the subgroup results with the meend list\n",
    "        subgroup_results[subgroup_range]['meend_list'] = meend_list\n",
    "    \n",
    "    # update the subgroup lists\n",
    "    save_lists_in_subgroups(subgroup_results)\n",
    "\n",
    "# Example usage\n",
    "update_kann_swar_and_meend_lists(subgroup_results)\n",
    "\n",
    "subgroup_results = load_lists_in_subgroups()\n",
    "\n",
    "# Print the updated results for each subgroup\n",
    "for subgroup_range, results in subgroup_results.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Kann Swar List: {results['kann_swar_list']}\")\n",
    "    print(f\"Meend List: {results['meend_list']}\")\n",
    "    print(f\"Swar List: {results['swar_list']}\")\n",
    "    print(f\"Lyrics List: {results['lyrics_list']}\")\n",
    "    print(f\"Swar Articulation Checks: {results['swar_articulation_checks']}\")\n",
    "    print(f\"Lyrics Articulation Checks: {results['lyrics_articulation_checks']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Segmentation and List Finalization\n",
    "- Performs further segmentation to finalize lists for each subgroup.\n",
    "\n",
    "#### Articulation Detection and Segmentation\n",
    "- Detects and segments **articulation** from:\n",
    "  - **Swar Row**: Updates the **Swar Articulation Checks** list.\n",
    "  - **Lyrics Row**: Updates the **Lyrics Articulation Checks** list.\n",
    "\n",
    "#### Word Segmentation\n",
    "- Applies **word segmentation** to:\n",
    "  - **Swar Row**: For images corresponding to **Swar Articulation Checks**.\n",
    "  - **Lyrics Row**: For images corresponding to **Lyrics Articulation Checks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup Range: (1, 6)\n",
      "Meend List: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row2_col1_x87_y108_w10_h13.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col5_x199_y111_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row2_col16_x415_y105_w7_h15.png'], [], ['Analysis\\\\multiple_page\\\\0_row2_col18_x458_y106_w5_h11.png'], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row3_col1_x93_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col2_x118_y134_w10_h4.png'], ['Analysis\\\\multiple_page\\\\0_row3_col3_x146_y128_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col4_x169_y129_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col6_x205_y125_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row3_col7_x228_y133_w11_h5.png'], ['Analysis\\\\multiple_page\\\\0_row3_col8_x252_y123_w11_h18.png'], ['Analysis\\\\multiple_page\\\\0_row3_col10_x275_y129_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row3_col11_x303_y128_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col12_x324_y121_w7_h18.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row3_col14_x338_y122_w43_h14_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row3_col14_x338_y122_w43_h14_seg2.png', 'Analysis\\\\multiple_page_segmented\\\\0_row3_col14_x338_y122_w43_h14_seg3.png', 'Analysis\\\\multiple_page_segmented\\\\0_row3_col14_x338_y122_w43_h14_seg4.png'], ['Analysis\\\\multiple_page\\\\0_row3_col15_x388_y127_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col16_x417_y128_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row3_col17_x439_y121_w8_h18.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row3_col18_x460_y121_w21_h25_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row3_col18_x460_y121_w21_h25_seg2.png'], ['Analysis\\\\multiple_page\\\\0_row3_col20_x495_y127_w16_h12.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row5_col1_x92_y162_w13_h16.png'], ['Analysis\\\\multiple_page\\\\0_row5_col2_x122_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col3_x147_y162_w8_h11.png'], ['Analysis\\\\multiple_page\\\\0_row5_col4_x168_y162_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col6_x205_y161_w15_h14.png', 'Analysis\\\\multiple_page\\\\0_row5_col6_x208_y154_w6_h5.png'], ['Analysis\\\\multiple_page\\\\0_row5_col7_x232_y162_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col8_x252_y162_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col10_x274_y162_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col11_x303_y161_w12_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col12_x323_y161_w12_h13.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row5_col14_x348_y156_w27_h13_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row5_col14_x348_y156_w27_h13_seg2.png', 'Analysis\\\\multiple_page_segmented\\\\0_row5_col14_x348_y156_w27_h13_seg3.png', 'Analysis\\\\multiple_page_segmented\\\\0_row5_col14_x348_y156_w27_h13_seg4.png'], ['Analysis\\\\multiple_page\\\\0_row5_col15_x388_y160_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col16_x418_y161_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col17_x438_y154_w9_h18.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row5_col18_x459_y160_w14_h9_seg1.png'], ['Analysis\\\\multiple_page\\\\0_row5_col19_x477_y159_w6_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col20_x497_y161_w10_h12.png'], ['Analysis\\\\multiple_page\\\\0_row5_col21_x514_y161_w5_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 13)\n",
      "Meend List: ['S', 'E', '', '', '', '', '', '', '', '', '', '', '', 'E', '', '', '']\n",
      "Kann Swar List: [[], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col9_x299_y288_w14_h15.png'], [], [], [], ['Analysis\\\\multiple_page\\\\0_row10_col13_x411_y289_w14_h15.png'], [], [], [], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row10_col1_x86_y312_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row10_col2_x108_y312_w11_h12.png'], ['Analysis\\\\multiple_page\\\\0_row10_col3_x131_y312_w10_h13.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col4_x152_y311_w17_h10_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row10_col4_x152_y311_w17_h10_seg2.png'], ['Analysis\\\\multiple_page\\\\0_row10_col5_x190_y308_w17_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col6_x220_y316_w9_h4.png'], ['Analysis\\\\multiple_page\\\\0_row10_col7_x240_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col8_x266_y308_w16_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col9_x301_y308_w17_h16.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col10_x326_y306_w24_h14_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row10_col10_x326_y306_w24_h14_seg2.png', 'Analysis\\\\multiple_page_segmented\\\\0_row10_col10_x326_y306_w24_h14_seg3.png'], ['Analysis\\\\multiple_page\\\\0_row10_col11_x364_y306_w8_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col12_x385_y307_w11_h17.png'], ['Analysis\\\\multiple_page\\\\0_row10_col13_x413_y308_w16_h16.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y307_w31_h14_lower_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y307_w31_h14_lower_seg2.png', 'Analysis\\\\multiple_page_segmented\\\\0_row10_col14_x433_y307_w31_h14_lower_seg3.png'], ['Analysis\\\\multiple_page\\\\0_row10_col15_x471_y312_w15_h16.png'], ['Analysis\\\\multiple_page\\\\0_row10_col16_x489_y312_w5_h15.png'], ['Analysis\\\\multiple_page\\\\0_row10_col17_x503_y317_w9_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row12_col1_x87_y342_w10_h13.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row12_col2_x110_y342_w9_h15_seg1.png'], ['Analysis\\\\multiple_page\\\\0_row12_col3_x132_y337_w10_h18.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row12_col4_x153_y341_w15_h12_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row12_col4_x153_y341_w15_h12_seg2.png'], ['Analysis\\\\multiple_page\\\\0_row12_col5_x189_y342_w17_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col6_x220_y342_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col7_x245_y342_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col8_x268_y342_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row12_col9_x304_y337_w14_h21.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row12_col10_x329_y342_w15_h11_seg1.png'], ['Analysis\\\\multiple_page\\\\0_row12_col11_x362_y343_w17_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col12_x388_y343_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col13_x415_y342_w11_h13.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row12_col14_x439_y342_w15_h11_seg1.png'], ['Analysis\\\\multiple_page\\\\0_row12_col15_x471_y343_w15_h12.png'], ['Analysis\\\\multiple_page\\\\0_row12_col17_x501_y343_w8_h12.png']]\n",
      "Swar Articulation Checks: [False, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "Lyrics Articulation Checks: [False, True, False, True, False, False, False, False, False, True, False, False, False, True, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (15, 21)\n",
      "Meend List: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "Kann Swar List: [['Analysis\\\\multiple_page\\\\0_row15_col1_x84_y378_w11_h13.png'], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col4_x155_y377_w10_h14.png'], ['Analysis\\\\multiple_page\\\\0_row15_col5_x188_y381_w9_h10.png'], [], [], [], [], [], [], [], ['Analysis\\\\multiple_page\\\\0_row15_col13_x413_y377_w6_h14.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\multiple_page\\\\0_row16_col1_x86_y399_w9_h12.png'], ['Analysis\\\\multiple_page\\\\0_row16_col2_x112_y404_w10_h3.png'], ['Analysis\\\\multiple_page\\\\0_row16_col3_x135_y398_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col4_x161_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col5_x190_y395_w10_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col6_x212_y403_w12_h4.png'], ['Analysis\\\\multiple_page\\\\0_row16_col7_x243_y396_w11_h16.png'], ['Analysis\\\\multiple_page\\\\0_row16_col8_x272_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col9_x302_y399_w11_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col10_x321_y392_w9_h17.png'], ['Analysis\\\\multiple_page_segmented\\\\0_row16_col11_x337_y394_w43_h13_seg1.png', 'Analysis\\\\multiple_page_segmented\\\\0_row16_col11_x337_y394_w43_h13_seg2.png', 'Analysis\\\\multiple_page_segmented\\\\0_row16_col11_x337_y394_w43_h13_seg3.png', 'Analysis\\\\multiple_page_segmented\\\\0_row16_col11_x337_y394_w43_h13_seg4.png'], ['Analysis\\\\multiple_page\\\\0_row16_col12_x386_y399_w9_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col13_x415_y399_w10_h13.png'], ['Analysis\\\\multiple_page\\\\0_row16_col14_x437_y392_w8_h17.png'], ['Analysis\\\\multiple_page\\\\0_row16_col15_x458_y393_w20_h24.png'], ['Analysis\\\\multiple_page\\\\0_row16_col17_x491_y398_w17_h13.png']]\n",
      "Lyrics List: [['Analysis\\\\multiple_page\\\\0_row18_col1_x86_y428_w16_h17.png'], ['Analysis\\\\multiple_page\\\\0_row18_col2_x112_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col3_x134_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col4_x159_y432_w11_h9.png'], ['Analysis\\\\multiple_page\\\\0_row18_col5_x190_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col6_x215_y432_w8_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col7_x245_y432_w12_h13.png'], ['Analysis\\\\multiple_page\\\\0_row18_col8_x270_y433_w13_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col9_x303_y433_w10_h16.png'], ['Analysis\\\\multiple_page\\\\0_row18_col10_x322_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col11_x340_y426_w14_h15.png', 'Analysis\\\\multiple_page\\\\0_row18_col11_x357_y431_w22_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col12_x388_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col13_x415_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col14_x436_y432_w8_h12.png'], ['Analysis\\\\multiple_page\\\\0_row18_col15_x457_y431_w12_h10.png'], ['Analysis\\\\multiple_page\\\\0_row18_col16_x473_y431_w7_h11.png'], ['Analysis\\\\multiple_page\\\\0_row18_col17_x492_y432_w10_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_erosion, binary_dilation, square\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# Define the path to the folder to store segmented images\n",
    "segmented_folder_path = os.path.normpath('Analysis/multiple_page_segmented')\n",
    "os.makedirs(segmented_folder_path, exist_ok=True)\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "    return thresh\n",
    "\n",
    "# Function to separate articulation in an image\n",
    "def separate_articulation(image):\n",
    "    processed_image = preprocess_image(image)\n",
    "    contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < h < 21 and w > 25:\n",
    "            upper_part = image[:y, :]\n",
    "            if upper_part.shape[0] > 0:\n",
    "                return upper_part, True  # Return the upper part and a flag indicating segmentation was successful\n",
    "            break\n",
    "    \n",
    "    return image, False  # Return the original image and a flag indicating no segmentation\n",
    "\n",
    "# Function to segment a word into multiple images\n",
    "def segment_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply simple binary thresholding and invert the image\n",
    "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Define structuring elements\n",
    "    structuring_element2 = np.ones((2, 2), dtype=bool)\n",
    "    structuring_element_erosion = square(3)\n",
    "\n",
    "    # Apply binary dilation to fill gaps\n",
    "    dilated = binary_dilation(binary, footprint=structuring_element2)\n",
    "\n",
    "    # Apply binary erosion to separate connected components\n",
    "    eroded = binary_erosion(dilated, footprint=structuring_element_erosion)\n",
    "    eroded = img_as_ubyte(eroded)  # Convert to uint8 for display purposes\n",
    "\n",
    "    # Perform vertical projection to find potential cut lines\n",
    "    vertical_projection = np.sum(eroded, axis=0)\n",
    "\n",
    "    # Find cut points by identifying valleys in the projection with heuristic\n",
    "    threshold = 0.15 * np.max(vertical_projection)\n",
    "    valleys = [x for x, y in enumerate(vertical_projection) if y < threshold]\n",
    "\n",
    "    # Apply heuristic: if two consecutive valleys are close, take the right one\n",
    "    cut_points = []\n",
    "    min_distance = 13\n",
    "    i = 0\n",
    "    while i < len(valleys) - 1:\n",
    "        if (valleys[i + 1] - valleys[i]) < min_distance:\n",
    "            cut_points.append(valleys[i + 1])\n",
    "            i += 2  # Skip the next valley since we took the right one\n",
    "        else:\n",
    "            cut_points.append(valleys[i])\n",
    "            i += 1\n",
    "    if i == len(valleys) - 1:\n",
    "        cut_points.append(valleys[i])  # Add the last valley if it's not processed\n",
    "\n",
    "    # Ensure no duplicate cut points and sort them\n",
    "    cut_points = sorted(set(cut_points))\n",
    "\n",
    "    # Separate the image at cut points\n",
    "    cut_images = []\n",
    "    start = 0\n",
    "    for cut_point in cut_points:\n",
    "        if cut_point - start > 10:  # Ensure segments are large enough\n",
    "            cut_image = img[:, start:cut_point]\n",
    "            cut_images.append(cut_image)\n",
    "            start = cut_point\n",
    "\n",
    "    # Add the last segment\n",
    "    cut_images.append(img[:, start:])\n",
    "\n",
    "    return cut_images\n",
    "\n",
    "# Function to merge segments based on height-to-width ratio\n",
    "def merge_segments(segments):\n",
    "    final_images = []\n",
    "    i = 0\n",
    "    while i < len(segments):\n",
    "        current_image = segments[i]\n",
    "        current_ratio = current_image.shape[0] / current_image.shape[1]\n",
    "\n",
    "        ratio_threshold = 1.8\n",
    "\n",
    "        if current_image.shape[0] > 35:\n",
    "            ratio_threshold = 2.9\n",
    "        \n",
    "        # If the ratio is greater than the threshold and it's the first segment\n",
    "        if current_ratio > ratio_threshold and i == 0:\n",
    "            # Merge with the next segment\n",
    "            if i + 1 < len(segments):\n",
    "                current_image = np.hstack((current_image, segments[i + 1]))\n",
    "                final_images.append(current_image)\n",
    "                i += 2\n",
    "            else:\n",
    "                final_images.append(current_image)\n",
    "                i += 1\n",
    "        # If two or more consecutive segments have a ratio greater than the threshold\n",
    "        elif i < len(segments) - 1 and (segments[i + 1].shape[0] / segments[i + 1].shape[1]) > ratio_threshold:\n",
    "            while i < len(segments) - 1 and (segments[i + 1].shape[0] / segments[i + 1].shape[1]) > ratio_threshold:\n",
    "                current_image = np.hstack((current_image, segments[i + 1]))\n",
    "                i += 1\n",
    "            final_images.append(current_image)\n",
    "            i += 1\n",
    "        # If the ratio is greater than the threshold and it's not the first segment\n",
    "        elif current_ratio > ratio_threshold and i != 0:\n",
    "            # Merge with the previous segment\n",
    "            if final_images:\n",
    "                final_images[-1] = np.hstack((final_images[-1], current_image))\n",
    "            else:\n",
    "                final_images.append(current_image)\n",
    "            i += 1\n",
    "        else:\n",
    "            final_images.append(current_image)\n",
    "            i += 1\n",
    "\n",
    "    return final_images\n",
    "\n",
    "# Function to process a single image, segment, and save the results in the provided folder\n",
    "def segment_word(image_path, output_folder):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return []\n",
    "    \n",
    "    # Segment the image\n",
    "    segmented_images = segment_image(img)\n",
    "    \n",
    "    # Merge segments based on height-to-width ratio\n",
    "    final_images = merge_segments(segmented_images)\n",
    "    \n",
    "    # Save the segmented images\n",
    "    image_base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    segmented_paths = []\n",
    "    for i, segmented_image in enumerate(final_images):\n",
    "        seg_image_path = os.path.normpath(os.path.join(output_folder, f'{image_base_name}_seg{i+1}.png'))\n",
    "        cv2.imwrite(seg_image_path, segmented_image)\n",
    "        segmented_paths.append(seg_image_path)\n",
    "    \n",
    "    return segmented_paths\n",
    "\n",
    "# Function to update lists based on segmentation\n",
    "def update_lists_with_segmentation(subgroup_results):\n",
    "    for subgroup_range, results in subgroup_results.items():\n",
    "        swar_list = results['swar_list']\n",
    "        lyrics_list = results['lyrics_list']\n",
    "        swar_articulation_checks = results['swar_articulation_checks']\n",
    "        lyrics_articulation_checks = results['lyrics_articulation_checks']\n",
    "        \n",
    "        # Apply articulation segmentation to swar row\n",
    "        for i in range(len(swar_list)):\n",
    "            if not swar_articulation_checks[i] and swar_list[i]:  # Check if articulation is False and the list is not empty\n",
    "                swar_image_path = swar_list[i][0]  # Get the image path\n",
    "                swar_image = cv2.imread(swar_image_path)  # Load the image\n",
    "                if swar_image is not None:\n",
    "                    segmented_image, is_segmented = separate_articulation(swar_image)\n",
    "                    if is_segmented:\n",
    "                        swar_articulation_checks[i] = True  # Update articulation check\n",
    "                        # Save the segmented image with the original name\n",
    "                        original_name = os.path.basename(swar_image_path)\n",
    "                        seg_image_path = os.path.normpath(os.path.join(segmented_folder_path, original_name))\n",
    "                        cv2.imwrite(seg_image_path, segmented_image)\n",
    "                        swar_list[i] = [seg_image_path]  # Update the list with the new image path\n",
    "        \n",
    "        # Apply articulation segmentation to lyrics row\n",
    "        for i in range(len(lyrics_list)):\n",
    "            if not lyrics_articulation_checks[i] and lyrics_list[i]:  # Check if articulation is False and the list is not empty\n",
    "                lyrics_image_path = lyrics_list[i][0]  # Get the image path\n",
    "                lyrics_image = cv2.imread(lyrics_image_path)  # Load the image\n",
    "                if lyrics_image is not None:\n",
    "                    segmented_image, is_segmented = separate_articulation(lyrics_image)\n",
    "                    if is_segmented:\n",
    "                        lyrics_articulation_checks[i] = True  # Update articulation check\n",
    "                        # Save the segmented image with the original name\n",
    "                        original_name = os.path.basename(lyrics_image_path)\n",
    "                        seg_image_path = os.path.normpath(os.path.join(segmented_folder_path, original_name))\n",
    "                        cv2.imwrite(seg_image_path, segmented_image)\n",
    "                        lyrics_list[i] = [seg_image_path]  # Update the list with the new image path\n",
    "        \n",
    "        # Apply word segmentation to swar row\n",
    "        for i in range(len(swar_list)):\n",
    "            if swar_articulation_checks[i] and swar_list[i]:  # Check if articulation is True and the list is not empty\n",
    "                swar_image_path = swar_list[i][0]  # Get the image path\n",
    "                segmented_paths = segment_word(swar_image_path, segmented_folder_path)\n",
    "                if segmented_paths:\n",
    "                    swar_list[i] = segmented_paths  # Update the list with segmented image paths\n",
    "        \n",
    "        # Apply word segmentation to lyrics row\n",
    "        for i in range(len(lyrics_list)):\n",
    "            if lyrics_articulation_checks[i] and lyrics_list[i]:  # Check if articulation is True and the list is not empty\n",
    "                lyrics_image_path = lyrics_list[i][0]  # Get the image path\n",
    "                segmented_paths = segment_word(lyrics_image_path, segmented_folder_path)\n",
    "                if segmented_paths:\n",
    "                    lyrics_list[i] = segmented_paths  # Update the list with segmented image paths\n",
    "        \n",
    "        # Update the results\n",
    "        subgroup_results[subgroup_range]['swar_list'] = swar_list\n",
    "        subgroup_results[subgroup_range]['lyrics_list'] = lyrics_list\n",
    "        subgroup_results[subgroup_range]['swar_articulation_checks'] = swar_articulation_checks\n",
    "        subgroup_results[subgroup_range]['lyrics_articulation_checks'] = lyrics_articulation_checks\n",
    "\n",
    "# Example usage\n",
    "update_lists_with_segmentation(subgroup_results)\n",
    "\n",
    "load_lists_in_subgroups()\n",
    "\n",
    "# Print the updated results for each subgroup\n",
    "for subgroup_range, results in subgroup_results.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Meend List: {results['meend_list']}\")\n",
    "    print(f\"Kann Swar List: {results['kann_swar_list']}\")\n",
    "    print(f\"Swar List: {results['swar_list']}\")\n",
    "    print(f\"Lyrics List: {results['lyrics_list']}\")\n",
    "    print(f\"Swar Articulation Checks: {results['swar_articulation_checks']}\")\n",
    "    print(f\"Lyrics Articulation Checks: {results['lyrics_articulation_checks']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for Kann Swar and Swar Rows\n",
    "- Predicts results for:\n",
    "  - **Kann Swar Row Images**: Uses the **Kann Swar List** for predictions.\n",
    "  - **Swar Row Images**: Uses the **Swar List** for predictions.\n",
    "- Generates predictions for each subgroup based on the respective lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Subgroup Range: (1, 6)\n",
      "Predicted Kann Swar List: [['म॑'], [], [], [], ['प'], [], [], [], [], [], [], [], ['रे'], [], ['रे'], []]\n",
      "Predicted Swar List: [['प'], ['-'], ['प'], ['प'], ['म॑'], ['-'], ['म॑'], ['ग'], ['ग'], ['रे'], ['म॑', '|', 'सा॑', 'म॑'], ['प'], ['ग'], ['रे'], ['नि़', 'रे॒'], ['सा']]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 13)\n",
      "Predicted Kann Swar List: [[], [], [], [], [], [], [], [], ['नि'], [], [], [], ['नि'], [], [], [], []]\n",
      "Predicted Swar List: [['प'], ['ग'], ['प'], ['ध', '|'], ['सा॑'], ['-'], ['सा॑'], ['सा॑'], ['सा॑'], ['रे॑', '|', 'म॑'], ['रे॑'], ['ग॑'], ['सा॑'], ['नि', '|', 'नि'], ['प़'], [')'], ['^^']]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (15, 21)\n",
      "Predicted Kann Swar List: [['म॑'], [], [], ['म॑'], ['ध'], [], [], [], [], [], [], [], ['रे'], [], [], []]\n",
      "Predicted Swar List: [['प'], ['|'], ['प'], ['प'], ['म॑'], ['-'], ['म'], ['ग'], ['ग'], ['रे'], ['सा॑', 'रे', 'ग', 'म॑'], ['प'], ['ग'], ['रे'], ['^^'], ['सा']]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from save_and_load import save_predictions, load_predictions\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cnn_recognizer_music_15_v1.h5')\n",
    "\n",
    "# Preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image at path: {image_path}\")\n",
    "    image = cv2.resize(image, (32, 32))  # Resize to match the model's input size\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Pass the image through the model and get predictions\n",
    "def predict_class(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)\n",
    "    max_probability = np.max(predictions, axis=1)\n",
    "    return predicted_class_index[0], max_probability[0]\n",
    "\n",
    "# Define the classes\n",
    "classes = [\"सा\", \"रे\", \"ग\", \"म\", \"प\", \"ध\", \"नि\", \"रे॒\", \"ग॒\", \"ध॒\", \"नि॒\", \"म॑\", \n",
    "           \"सा\\u0951\", \"रे\\u0951\", \"ग\\u0951\", \"म\\u0951\", \"प\\u0951\", \"ध\\u0951\", \"रे॒\\u0951\", \"ग॒\\u0951\", \"म॑'\", \n",
    "           \"म\\u093C\", \"म॑\\u093C\", \"प\\u093C\", \"ध॒\\u093C\", \"ध\\u093C\", \"नि॒\\u093C\", \"नि\\u093C\", \n",
    "           \")\", \",\", \"-\", \"४\", \"O\", \"(\", \"^^\", \"X\", \"३\", \"२\", \"|\", \"<_>\"]\n",
    "\n",
    "\n",
    "# classes = [\"saa\", \"re\", \"ga\", \"ma\", \"pa\", \"dha\", \"ni\", \"re-\", \"ga-\", \"dha-\", \"ni-\", \"ma#\", \n",
    "#            \"saa'\", \"re'\", \"ga'\", \"ma'\", \"pa'\", \"dha'\", \"re-'\", \"ga-'\", \"ma#'\", \n",
    "#            \"ma,\", \"ma#,\", \"pa,\", \"dha-,\", \"dha,\", \"ni-,\", \"ni,\", \n",
    "#            \",\", \"-\"]\n",
    "\n",
    "# Function to generate new lists with predicted class names\n",
    "def generate_predicted_lists(subgroup_results):\n",
    "    predicted_results = {}\n",
    "    \n",
    "    for subgroup_range, results in subgroup_results.items():\n",
    "        # Initialize new lists for predicted class names\n",
    "        predicted_swar_list = []\n",
    "        predicted_kann_swar_list = []  # Add this if you have kann_swar_list\n",
    "        \n",
    "        # Predict class names for swar_list\n",
    "        for image_paths in results['swar_list']:\n",
    "            if image_paths:  # Check if the list is not empty\n",
    "                predicted_classes = []\n",
    "                for image_path in image_paths:\n",
    "                    predicted_class_index, _ = predict_class(image_path)\n",
    "                    predicted_class_name = classes[predicted_class_index]\n",
    "                    predicted_classes.append(predicted_class_name)\n",
    "                predicted_swar_list.append(predicted_classes)\n",
    "            else:\n",
    "                predicted_swar_list.append([])  # Append empty list for empty entries\n",
    "        \n",
    "        # Predict class names for kann_swar_list (if applicable)\n",
    "        for image_paths in results['kann_swar_list']:\n",
    "            if image_paths:  # Check if the list is not empty\n",
    "                predicted_classes = []\n",
    "                for image_path in image_paths:\n",
    "                    predicted_class_index, _ = predict_class(image_path)\n",
    "                    predicted_class_name = classes[predicted_class_index]\n",
    "                    predicted_classes.append(predicted_class_name)\n",
    "                predicted_kann_swar_list.append(predicted_classes)\n",
    "            else:\n",
    "                predicted_kann_swar_list.append([])  # Append empty list for empty entries\n",
    "        \n",
    "        # Store the predicted results for this subgroup\n",
    "        predicted_results[subgroup_range] = {\n",
    "            'predicted_swar_list': predicted_swar_list,\n",
    "            'predicted_kann_swar_list': predicted_kann_swar_list  \n",
    "        }\n",
    "    \n",
    "    return predicted_results\n",
    "\n",
    "subgroup_results = load_lists_in_subgroups()\n",
    "\n",
    "# Example usage\n",
    "# Assuming subgroup_results is the dictionary you provided\n",
    "predicted_results = generate_predicted_lists(subgroup_results)\n",
    "\n",
    "save_predictions(predicted_results)\n",
    "\n",
    "\n",
    "\n",
    "def print_predictions(predictions):\n",
    "    \"\"\"Prints results with original formatting\"\"\"\n",
    "    for subgroup_range, results in predictions.items():\n",
    "        print(f\"\\nSubgroup Range: {subgroup_range}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Predicted Kann Swar List:\")\n",
    "        for i, item in enumerate(results['predicted_kann_swar_list']):\n",
    "            print(f\"  Position {i}: {item}\")\n",
    "        \n",
    "        print(\"\\nPredicted Swar List:\") \n",
    "        for i, item in enumerate(results['predicted_swar_list']):\n",
    "            print(f\"  Position {i}: {item}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "predictions = load_predictions()\n",
    "\n",
    "if predictions:\n",
    "    print_predictions(predictions)\n",
    "\n",
    "# # Print the predicted results\n",
    "# for subgroup_range, results in predicted_results.items():\n",
    "#     print(f\"Subgroup Range: {subgroup_range}\")\n",
    "#     print(f\"Predicted Kann Swar List: {results['predicted_kann_swar_list']}\") \n",
    "#     print(f\"Predicted Swar List: {results['predicted_swar_list']}\")\n",
    "#     print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
